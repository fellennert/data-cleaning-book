[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data cleaning for social scientists",
    "section": "",
    "text": "This is the script for a two-day workshop on data cleaning for the social sciences. I assume you to be familiar with basic R concepts such as the different data types and how to index them, the general structure of the syntax, and how to make function calls.\nIn the following box, you can see the introductory slides for a workshop I gave at the Céntre Emile Durkheim at Bordeaux:\n\nknitr::include_url(\"file:///Users/felixlennert/Documents/phd/teaching/data-prep_2days/welcome.html#/title-slide\")\n\n\n\nIn the 21st century, social scientists are able to tap into wells of data that are deeper than ever before. Not only can we use more designed data, i.e., data that have been generated with the clear goal of performing research using them, such as survey data, than ever. Also the rise of the internet as a sensor for human behavior provides us with new opportunities.\nGiven their variety, these data sets may all come in different structures, and if we want to leverage them to improve our understanding of the world, we need to reshape them properly. Therefore, we are in need for tools that are capable and flexible enough to work with all different kinds of data while remaining easily accessible. In my opinion, R (R Core Team 2017), RStudio, and the tidyverse packages (Wickham et al. 2019) strike a good balance here. R is a powerful, flexible, statistical programming language, RStudio serves as a convenient Graphic User Interface (GUI) which can be used freely by researchers, and, finally, the tidyverse, and its adjacent packages, are a collection of packages with concisely defined use-cases, consistent syntax that cover a wide array of data science applications from acquiring data, cleaning data, transforming data, to finally visualizing them, and using them to draw inferences on the underlying real-world data-generation processes.\nThis script is going to introduce you to the following things: we start with the basics, i.e., the RStudio environment, projects, and how to read in data. Thereafter, I will introduce you to the idea behind “tidy data” (Wickham 2014). This describes a particular way of structuring data and is necessary insofar as basically all tidyverse packages require data in this structure to function properly. Then, once the data set is in a tidy format, we can delve into the actual transformation process. Finally, an extensive and thorough introduction to data visualization will be provided.\n\n\nThis stuff is far from trivial. Just like learning a new language, mastering it requires hard and consistent effort to eventually master coding in R. In order to facilitate your learning, I will link to as many external resources as possible and provide all data sets used in the script so that you can run and adapt (“play with”) the code yourself.\nLet me also tell you that you will run into problems. Constantly. Therefore, googling error messages takes up considerable space in every thorough data analysis endeavor. Usually, you can just copy the error message and throw it into Google. The tricky part here is to strike a balance between staying generalizable enough (i.e., do not include your self-chosen file names or replace them by the data type, i.e., tibble or df – Data.Frame). Platforms to find help and further guidance are for instance StackOverflow and the RStudio forum.\n\n\n\n\nR Core Team. 2017. R: A Language and Environment for Statistical Computing. Vienna: R Foundation for Statistical Computing. https://www.R-project.org.\n\n\nWickham, Hadley. 2014. “Tidy Data.” Journal of Statistical Software 59 (10). https://doi.org/10.18637/jss.v059.i10.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the Tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "See Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "R Core Team. 2017. R: A Language and Environment for Statistical\nComputing. Vienna: R Foundation for Statistical Computing. https://www.R-project.org.\n\n\nWickham, Hadley. 2014. “Tidy Data.” Journal of\nStatistical Software 59 (10). https://doi.org/10.18637/jss.v059.i10.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy\nMcGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome\nto the Tidyverse.” Journal of Open Source Software 4\n(43): 1686. https://doi.org/10.21105/joss.01686."
  },
  {
    "objectID": "tidy-data.html",
    "href": "tidy-data.html",
    "title": "2  Tidy data",
    "section": "",
    "text": "Before you learn how to tidy and wrangle data, you need to know how you want your data set to actually look like, i.e., what the desired outcome of the entire process of tidying your data set is. The tidyverse is a collection of packages which share an underlying philosophy: they are tidy. This means, that they (preferably) take tidy data as inputs and output tidy data. In the following, I will, first, introduce you to the concept of tidy data as developed by Hadley Wickham (Wickham 2014). Second, tidyr is introduced (wickham2020b?). Its goal is to provide you with functions that facilitate tidying data sets. Beyond, I will provide you some examples of how to create tibbles using functions from the tibble package (muller2020?). Moreover, the pipe from the magrittr package is introduced.\nPlease note that tidying and cleaning data are not equivalent: I refer to tidying data as to bringing data in a tidy format. Cleaning data, however, can encompass way more than this: parsing columns in the right format (using readr, for instance), imputation of missing values, address the problem of typos, etc."
  },
  {
    "objectID": "tidy-data.html#column-headers-are-values",
    "href": "tidy-data.html#column-headers-are-values",
    "title": "2  Tidy data",
    "section": "4.1 Column headers are values",
    "text": "4.1 Column headers are values\nA data set of this form would look like this:\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\ntibble_value_headers <- tibble(\n  manufacturer = c(\"Audi\", \"BMW\", \"Mercedes\", \"Opel\", \"VW\"),\n  `3 cyl` = sample(20, 5, replace = TRUE),\n  `4 cyl` = sample(50:100, 5, replace = TRUE),\n  `5 cyl` = sample(10, 5, replace = TRUE),\n  `6 cyl` = sample(30:50, 5, replace = TRUE),\n  `8 cyl` = sample(20:40, 5, replace = TRUE),\n  `10 cyl` = sample(10, 5, replace = TRUE),\n  `12 cyl` = sample(20, 5, replace = TRUE),\n  `16 cyl` = rep(0, 5)\n)\n\ntibble_value_headers\n\n# A tibble: 5 × 9\n  manufacturer `3 cyl` `4 cyl` `5 cyl` `6 cyl` `8 cyl` `10 cyl` `12 cyl` 16 cy…¹\n  <chr>          <int>   <int>   <int>   <int>   <int>    <int>    <int>   <dbl>\n1 Audi               8      66       7      41      36        6       14       0\n2 BMW                1      79       2      41      25        5       19       0\n3 Mercedes          17      66       4      47      29       10       14       0\n4 Opel              13      88       7      42      28        8        2       0\n5 VW                12      53       4      47      31        3       11       0\n# … with abbreviated variable name ¹​`16 cyl`\n\n\nYou can create a tibble by column using the tibble function. Column names need to be specified and linked to vectors of either the same length or length one.\nThis data set basically consists of three variables: German car manufacturer, number of cylinders, and frequency. To make the data set tidy, it has to consist of three columns depicting the three respective variables. This operation is called pivoting the non-variable columns into two-column key-value pairs. As the data set will thereafter contain fewer columns and more rows than before, it will have become longer (or taller). Hence, the tidyr function is called pivot_longer().\n\nger_car_manufacturer_longer <- tibble_value_headers |> \n  pivot_longer(-manufacturer, names_to = \"cylinders\", values_to = \"frequency\")\nger_car_manufacturer_longer\n\n# A tibble: 40 × 3\n   manufacturer cylinders frequency\n   <chr>        <chr>         <dbl>\n 1 Audi         3 cyl             8\n 2 Audi         4 cyl            66\n 3 Audi         5 cyl             7\n 4 Audi         6 cyl            41\n 5 Audi         8 cyl            36\n 6 Audi         10 cyl            6\n 7 Audi         12 cyl           14\n 8 Audi         16 cyl            0\n 9 BMW          3 cyl             1\n10 BMW          4 cyl            79\n# … with 30 more rows\n\n\nIn the function call, you need to specify the following: if you were not to use the pipe, the first argument would be the tibble you are manipulating. Then, you look at the column you want to keep. Here, it is the car manufacturer. This means that all columns but manufacturer will be crammed into two new ones: one will contain the columns’ names, the other one their values. How are those new column supposed to be named? That can be specified in the names_to = and values_to =arguments. Please note that you need to provide them a character vector, hence, surround your parameters with quotation marks. As a rule of thumb for all tidyverse packages: If it is a new column name you provide, surround it with quotation marks. If it is one that already exists – like, here, manufacturer, then you do not need the quotation marks."
  },
  {
    "objectID": "tidy-data.html#variables-in-both-rows-and-columns",
    "href": "tidy-data.html#variables-in-both-rows-and-columns",
    "title": "2  Tidy data",
    "section": "4.2 Variables in both rows and columns",
    "text": "4.2 Variables in both rows and columns\nYou have this data set:\n\ncar_models_fuel <- tribble(\n  ~manufacturer, ~model, ~cylinders, ~fuel_consumption_type, ~fuel_consumption_per_100km,\n  \"VW\", \"Golf\", 4, \"urban\", 5.2,\n  \"VW\", \"Golf\", 4, \"extra urban\", 4.5,\n  \"Opel\", \"Adam\", 4, \"urban\", 4.9,\n  \"Opel\", \"Adam\", 4, \"extra urban\", 4.1\n  )\ncar_models_fuel\n\n# A tibble: 4 × 5\n  manufacturer model cylinders fuel_consumption_type fuel_consumption_per_100km\n  <chr>        <chr>     <dbl> <chr>                                      <dbl>\n1 VW           Golf          4 urban                                        5.2\n2 VW           Golf          4 extra urban                                  4.5\n3 Opel         Adam          4 urban                                        4.9\n4 Opel         Adam          4 extra urban                                  4.1\n\n\nIt was created using the tribble function: tibbles can also be created by row. First, the column names need to be specified by putting a tilde (~) in front of them. Then, you can put in values separated by commas. Please note that the number of values needs to be a multiple of the number of columns.\nIn this data set, there are basically five variables: manufacturer, model, cylinders, urban fuel consumption, and extra urban fuel consumption. However, the column fuel_consumption_type does not store a variable but the names of two variables. Hence, you need to fix this to make the data set tidy. Because this encompasses reducing the number of rows, the data set becomes wider. The function to achieve this is therefore called pivot_wider() and the inverse of pivot_longer().\n\ncar_models_fuel_tidy <- car_models_fuel |> \n  pivot_wider(\n    names_from = fuel_consumption_type, \n    values_from = fuel_consumption_per_100km\n    )\n\ncar_models_fuel_tidy\n\n# A tibble: 2 × 5\n  manufacturer model cylinders urban `extra urban`\n  <chr>        <chr>     <dbl> <dbl>         <dbl>\n1 VW           Golf          4   5.2           4.5\n2 Opel         Adam          4   4.9           4.1\n\n\nHere, you only need to specify the columns you fetch the names and values from. As they both do already exist, you do not need to wrap them in quotation marks."
  },
  {
    "objectID": "tidy-data.html#multiple-variables-in-one-column",
    "href": "tidy-data.html#multiple-variables-in-one-column",
    "title": "2  Tidy data",
    "section": "4.3 Multiple variables in one column",
    "text": "4.3 Multiple variables in one column\nNow, however, there is a problem with the cylinders: their number should be depicted in a numeric vector. We could achieve this by either parsing it to a numeric vector:\n\nparse_number(ger_car_manufacturer_longer$cylinders)\n\n [1]  3  4  5  6  8 10 12 16  3  4  5  6  8 10 12 16  3  4  5  6  8 10 12 16  3\n[26]  4  5  6  8 10 12 16  3  4  5  6  8 10 12 16\n\n\nOn the other hand, we can also use a handy function from tidyr called separate() and afterwards drop the unnecessary column:\n\nger_car_manufacturer_longer_sep_cyl <- ger_car_manufacturer_longer |> # first, take the tibble\n  separate(cylinders, into = c(\"cylinders\", \"drop_it\"), sep = \" \") |> # and then split the column \"cylinders\" into two\n  select(-drop_it) # you will learn about this in the lesson on dplyr  # and then drop one column from the tibble\n\nIf there are two (or actually more) relevant values in one column, you can simply let out the dropping process and easily split them into multiple columns. By default, the sep = argument divides the content by all non-alphanumeric characters (every character that is not a letter, number, or space) it contains.\nPlease note that the new column is still in character format. We can change this using as.numeric():\n\nger_car_manufacturer_longer_sep_cyl$cylinders <- as.numeric(ger_car_manufacturer_longer_sep_cyl$cylinders)\n\nFurthermore, you might want to sort your data in a different manner. If you want to do this by cylinders, it would look like this:\n\narrange(ger_car_manufacturer_longer_sep_cyl, cylinders)\n\n# A tibble: 40 × 3\n   manufacturer cylinders frequency\n   <chr>            <dbl>     <dbl>\n 1 Audi                 3         8\n 2 BMW                  3         1\n 3 Mercedes             3        17\n 4 Opel                 3        13\n 5 VW                   3        12\n 6 Audi                 4        66\n 7 BMW                  4        79\n 8 Mercedes             4        66\n 9 Opel                 4        88\n10 VW                   4        53\n# … with 30 more rows\n\n\n\n4.3.1 Insertion: the pipe\nHave you noticed the |>? That’s the pipe. It can be considered a conjunction in coding. Usually, you will use it when working with tibbles. What it does is pretty straight-forward: it takes what is on its left – the input – and provides it to the function on its right as the first argument. Hence, the code in the last chunk, which looks like this\n\narrange(ger_car_manufacturer_longer_sep_cyl, cylinders)\n\n# A tibble: 40 × 3\n   manufacturer cylinders frequency\n   <chr>            <dbl>     <dbl>\n 1 Audi                 3         8\n 2 BMW                  3         1\n 3 Mercedes             3        17\n 4 Opel                 3        13\n 5 VW                   3        12\n 6 Audi                 4        66\n 7 BMW                  4        79\n 8 Mercedes             4        66\n 9 Opel                 4        88\n10 VW                   4        53\n# … with 30 more rows\n\n\ncould have also been written like this\n\nger_car_manufacturer_longer_sep_cyl |> arrange(cylinders)\n\n# A tibble: 40 × 3\n   manufacturer cylinders frequency\n   <chr>            <dbl>     <dbl>\n 1 Audi                 3         8\n 2 BMW                  3         1\n 3 Mercedes             3        17\n 4 Opel                 3        13\n 5 VW                   3        12\n 6 Audi                 4        66\n 7 BMW                  4        79\n 8 Mercedes             4        66\n 9 Opel                 4        88\n10 VW                   4        53\n# … with 30 more rows\n\n\nbecause the tibble is the first argument in the function call.\nBecause the pipe (its precedessor was %>%) has really gained traction in the R community, many functions are now optimized for being used with the pipe. However, there are still some around which are not. A function for fitting a basic linear model with one dependent and one independent variable which are both stored in a tibble looks like this: lm(formula = dv ~ iv, data = tibble). Here, the tibble is not the first argument. To be able to fit a linear model in a “pipeline,” you need to employ a little hack: you can use an underscore _ as a placeholder. Here, it is important that the argument is named.\nLet’s check out the effect the number of cylinders has on the number of models:\n\nger_car_manufacturer_longer_sep_cyl |> \n  lm(frequency ~ cylinders, data = _) |> \n  summary()\n\n\nCall:\nlm(formula = frequency ~ cylinders, data = ger_car_manufacturer_longer_sep_cyl)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-34.679 -14.974  -0.504  13.438  55.027 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  43.7964     7.2138   6.071 4.55e-07 ***\ncylinders    -2.7058     0.8003  -3.381  0.00168 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.02 on 38 degrees of freedom\nMultiple R-squared:  0.2313,    Adjusted R-squared:  0.211 \nF-statistic: 11.43 on 1 and 38 DF,  p-value: 0.001684\n\n\nAs |> is a bit tedious to type, there exist shortcuts: shift-ctrl-m on a Mac, shift-strg-m on a Windows machine."
  },
  {
    "objectID": "tidy-data.html#further-functionalities",
    "href": "tidy-data.html#further-functionalities",
    "title": "2  Tidy data",
    "section": "4.4 Further functionalities",
    "text": "4.4 Further functionalities\n\n4.4.1 Splitting and merging cells\nIf there are multiple values in one column/cell and you want to split them and put them into two rows instead of columns, tidyr offers you the separate_rows() function.\n\ngerman_cars_vec <- c(Audi = \"A1, A3, A4, A5, A6, A7, A8\", \n                     BMW = \"1 Series, 2 Series, 3 Series, 4 Series, 5 Series, 6 Series, 7 Series, 8 Series\")\ngerman_cars_tbl <- enframe(\n  german_cars_vec, \n  name = \"brand\", \n  value = \"model\"\n  )\n\ngerman_cars_tbl\n\n# A tibble: 2 × 2\n  brand model                                                                   \n  <chr> <chr>                                                                   \n1 Audi  A1, A3, A4, A5, A6, A7, A8                                              \n2 BMW   1 Series, 2 Series, 3 Series, 4 Series, 5 Series, 6 Series, 7 Series, 8…\n\ntidy_german_cars_tbl <- german_cars_tbl |> \n  separate_rows(model, sep = \", \")\n\nenframe() enables you to create a tibble from a (named) vector. It outputs a tibble with two columns (name and value by default): name contains the names of the elements (if the elements are unnamed, it contains a serial number), value the element. Both can be renamed in the function call by providing a character vector.\nIf you want to achieve the opposite, i.e., merge cells’ content, you can use the counterpart, unite(). Let’s take the following dataframe which consists of the names of the professors of the Institute for Political Science of the University of Regensburg:\n\nprofessor_names_df <- data.frame(first_name = c(\"Karlfriedrich\", \"Martin\", \"Jerzy\", \"Stephan\", \"Melanie\"),\n                                 last_name = c(\"Herb\", \"Sebaldt\", \"Maćków\", \"Bierling\", \"Walter-Rogg\"))\n\nprofessor_names_tbl <- professor_names_df |> \n  as_tibble() |> \n  unite(first_name, last_name, col = \"name\", sep = \" \", remove = TRUE, na.rm = FALSE)\n\nprofessor_names_tbl\n\n# A tibble: 5 × 1\n  name               \n  <chr>              \n1 Karlfriedrich Herb \n2 Martin Sebaldt     \n3 Jerzy Maćków       \n4 Stephan Bierling   \n5 Melanie Walter-Rogg\n\n\nunite() takes the tibble it should be applied to as the first argument (not necessary if you use the pipe). Then, it takes the two or more columns as arguments (actually, this is not necessary if you want to unite all columns). col = takes a character vector to specify the name of the resulting, new column. remove = TRUE indicates that the columns that are united are removed as well. You can, of course, set it to false, too. na.rm = FALSE finally indicates that missing values are not to be removed prior to the uniting process.\nHere, the final variant of creating tibbles is introduced as well: you can apply the function as_tibble() to a data frame and it will then be transformed into a tibble."
  },
  {
    "objectID": "projects_readr.html",
    "href": "projects_readr.html",
    "title": "1  Introduction to RStudio Projects and readr",
    "section": "",
    "text": "As some of you are beginners, it might be hard for you to see the point in setting up Projects and a GitHub account already. The intermediate and advanced users among you, who are not familiar with projects and GitHub yet though, might also wonder what they would need it for: working with R has gone pretty well in the past, so why should you change this running system?\nI start out making points on why using Projects is useful. Then, I will provide step-by-step guidance on how to set them up. Since using GitHub is not that straight-forward, I will motivate why to use it and then link to a bigger tutorial covering the setup process (again by Jennifer Bryan, a statistic professor who also works at RStudio)."
  },
  {
    "objectID": "projects_readr.html#rstudio-projects",
    "href": "projects_readr.html#rstudio-projects",
    "title": "1  Introduction to RStudio Projects and readr",
    "section": "1.1 RStudio Projects",
    "text": "1.1 RStudio Projects\n\n1.1.1 Motivation\nDisclaimer: those things might not be entirely clear right away. However, I am deeply convinced that it is important that you use R and RStudio properly from the start. Otherwise it won’t be as easy to re-build the right habits.\nIf you analyze data with R, one of the first things you do is to load in the data that you want to perform your analyses on. Then, you perform your analyses on them, and save the results in the (probably) same directory.\nWhen you load a data set into R, you might use the readr package and do read_csv(absolute_file_path.csv). This becomes fairly painful if you need to read in more than one data set. Then, relative paths (i.e., where you start from a certain point in your file structure, e.g., your file folder) become more useful. How you CAN go across this is to use the setwd(absolute_file_path_to_your_directory) function. Here, set stands for set and wd stands for working directory. If you are not sure about what the current working directory actually is, you can use getwd() which is the equivalent to setwd(file_path). This enables you to read in a data set – if the file is in the working directory – by only using read_csv(file_name.csv).\nHowever, if you have ever worked on an R project with other people in a group and exchanged scripts regularly, you may have encountered one of the big problems with this setwd(file_path) approach: as it only takes absolute paths like this one: “/Users/felixlennert/Library/Mobile Documents/comappleCloudDocs/phd/teaching/hhs-stockholm/fall2021/scripts/”, no other person will be able to run this script without making any changes1. Just to be clear: there are no two machines which have the exact same file structure.\nThis is where RStudio Projects come into play: they make every file path relative. The Project file (ends with .Rproj) basically sets the working directory to the folder it is in. Hence, if you want to send your work to a peer or a teacher, just send a folder which also contains the .Rproj file and they will be able to work on your project without the hassle of pasting file paths into setwd() commands.\n\n\n1.1.2 How to create an RStudio Project?\nI strongly suggest that you set up a project which is dedicated to this workshop\n\nIn RStudio, click File >> New Project…\nA windows pops up which lets you select between “New Directory”, “Existing Directory”, and “Version Control.” The first option creates a new folder which is named after your project, the second one “associates a project with an existing working directory,” and the third one only applies to version control (like, for instance, GitHub) users. I suggest that you click “New Directory”.\nNow you need to specify the type of the project (Empty project, R package, or Shiny Web Application). In our case, you will need a “new project.” Hit it!\n\nThe final step is to choose the folder the project will live in. If you have already created a folder which is dedicated to this course, choose this one, and let the project live in there as a sub-directory.\nWhen you write code for our course in the future, you first open the R project – by double-clicking the .Rproj file – and then create either a new script or open a former one (e.g., by going through the “Files” tab in the respective pane which will show the right directory already.)"
  },
  {
    "objectID": "projects_readr.html#the-working-directory-in-r",
    "href": "projects_readr.html#the-working-directory-in-r",
    "title": "1  Introduction to RStudio Projects and readr",
    "section": "1.2 The working directory in R",
    "text": "1.2 The working directory in R\nAs mentioned when introducing RStudio Projects, there are two kinds of file paths you can provide R with: absolute and relative paths.\nThe absolute path for this script on my machine looks like this: “/Users/felixlennert/Documents/phd/teaching/data-prep_2days/data-cleaning-book/tidy-data.qmd”.\nIf you are on a Windows machine and copy file paths: R uses the file path separator \\ as a so-called escape character – hence, it does not recognize it as a file path separator. You can address this problem by either using double back-slashes \\\\ or using a normal slash, /, instead.\nThere is always a working directory you are in. You can obtain your working directory using getwd(). Relative paths then just build upon it. If you want to change your working directory, use setwd().\nPlease note that I included the former two paragraphs just for the record. You should never use absolute paths, except for if you are planning to keep the same machine for the rest of your life and never change any of your file structure. You are not. Hence, please use RStudio Projects.2\nIf you are using RStudio Projects, your working directory defaults to the folder your .Rproj file is stored in. So, I guess you could immediately see the merit of using RStudio projects: by using them, you can do away with all the faff of setting working directories, copying crazy long absolute paths, and, relatedly, searching for typos in them.\nIf you are working in RMarkdown, or quarto, its successor, the working directory is where your RMarkdown document is stored in.\n\n1.2.1 Further links\n\nHadley Wickham and Garrett Grolemund wrote an entire chapter in R4DS on Projects.\n\nNeed more motivation? Jennifer Bryan tells you under which circumstances she would set your machine on fire: Project-oriented workflow.\nIf you have created your project folder and are now unsure how to structure it, read Chris von Csefalvay’s blog post on how to do it."
  },
  {
    "objectID": "projects_readr.html#readrs-general-functions",
    "href": "projects_readr.html#readrs-general-functions",
    "title": "1  Introduction to RStudio Projects and readr",
    "section": "1.3 readr’s general functions…",
    "text": "1.3 readr’s general functions…\nIn general, importing data with readr is pretty hassle-free: the hardest thing about it is calling the right function. It usually takes care of the rest itself, parsing columns properly, etc. However, sometimes you need to specify additional arguments.\nThe following unordered list shows the most common read_*() functions. Usually, you can simply provide them a file path and they load in the data and return a Tibble. If your data is in a compressed file with the extension .gz, .bz2, .xz, or .zip, readr will automatically uncompress it. If the file is stored online, you can provide a URL starting with http://, https://, ftp://, or ftps://. readr will automatically take care of the download process.\n\nread_csv(\"file.csv\") reads comma delimited files\n\nread_csv2(\"file.csv\") reads semi-colon delimited files and treats commas as decimal separator\n\nread_delim(\"file.txt\", delim = \"|\") reads files which are delimited by whatever delimiter you specify (| in this case)\n\nread_fwf(\"file.fwf\", col_positions = c(1, 3, 5)) reads fixed width files. Here, some sort of data on the columns must be provided, e.g., their positions in the file\n\nIf the values are separated by whitespace, you can also use read_tsv(\"file.tsv\") or read_table(\"file.tsv\")"
  },
  {
    "objectID": "projects_readr.html#and-their-additional-arguments",
    "href": "projects_readr.html#and-their-additional-arguments",
    "title": "1  Introduction to RStudio Projects and readr",
    "section": "1.4 …and their additional arguments",
    "text": "1.4 …and their additional arguments\nAlso, all these functions share certain arguments which just need to be included in the call. In the following, I will enumerate the most useful ones.\n\nIf your file does not have a header (most of the time, column names), provide col_names = FALSE. The resulting Tibble will have X1 … Xn as column names\n\nIf your file does not have column names, but you want the resulting Tibble to have some, you can specify them with col_names = c(\"a\", \"b\", \"c\"). It takes a character vector.\n\nIf there are rows you do not want to be considered, you can use skip =. For instance, read_csv(\"file.csv\", skip = 6) reads everything but the first six data rows (the very first row is not taken into consideration as well)\n\nSometimes the original creator of your data set might go across missing values differently than you would want it to. na = can be used to specify which values shall be considered missing. If your missings are coded as 99 and 999, for instance, you can address that in the read-in process already by using read_csv(\"file.csv\", na = c(\"99\", \"999\")). Please note that it takes a character vector as argument\n\nIn some data sets, the first rows consists of comments that start with particular signs or special characters. Using comment = allows you to skip these lines. For instance, read_csv(\"file.csv\", comment = \"#\") drops all the rows that beginn with a hash.\n\n\n1.4.1 Column types\nAs you have already learned in the script before, a Tibble consists of multiple vectors of the same length. The vectors can be of different types. When you read in data using readr, it will print out the column types it has guessed. When you read in data, you must ascribe it to an object in your environment. The following code reads in a .csv file with data on the 100 most-played songs on Spotify in 2018 and stores it in the object spotify_top100_2018.\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n# library(readr) --> no need to load readr, it's part of the core tidyverse\nspotify_top100_2018 <- read_csv(\"https://www.dropbox.com/s/z8d6irpjdohdktf/spotify2018.csv?dl=1\")\n\nRows: 100 Columns: 16\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): id, name, artists\ndbl (13): danceability, energy, key, loudness, mode, speechiness, acousticne...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nIf your data is well-behaved, R will guess the vector types correctly and everything will run smoothly. However, sooner or later you will stumble across a data set which is not well-behaved. This is where knowing how to fine-tune your parsing process up-front will eventually save you a lot of head scratching.\nBut how does parsing actually look like. Well, readr’s parsing functions take a character vector and return a more specialized vector.\n\nparse_double(c(\"1\", \"2\", \"3\"))\n\n[1] 1 2 3\n\n\nSo far so good. What readrdoes when it reads in your data sets is that it takes the first 1,000 values of every column and tries to guess the correct data type. This can be emulated using guess_parser() and parse_guess(). Both functions take a character vector as input. The former one returns the guessed type, the latter returns a vector which is parsed to the type it has guessed.\n\nguess_parser(\"2009-04-23\")\n\n[1] \"date\"\n\nstr(parse_guess(\"2009-04-23\"))\n\n Date[1:1], format: \"2009-04-23\"\n\n\nThe heuristic it uses is fairly simple yet robust. However, there are common cases when you might run into problems with different data types. In the following, I will show you the two most common ones. The first one regards numeric data, the second one data on date and time.\n\n1.4.1.1 Numbers\nParsing numbers should be straight-forward, right, so what could possibly go wrong?\nWell…\n\nDecimal points\n\nSpecial characters ($, %, §, €)\n\nSo-called grouping characters such as 1,000,000 (USA) or 1.000.000 (Germany) or 1’000’000 (Switzerland)\n\nThe problem with decimale points (– and commas) can be addresses by specifying a locale. Compare:\n\nparse_double(\"1,3\")\n\nWarning: 1 parsing failure.\nrow col               expected actual\n  1  -- no trailing characters    1,3\n\n\n[1] NA\nattr(,\"problems\")\n# A tibble: 1 × 4\n    row   col expected               actual\n  <int> <int> <chr>                  <chr> \n1     1    NA no trailing characters 1,3   \n\nparse_double(\"1,3\", locale = locale(decimal_mark = \",\"))\n\n[1] 1.3\n\n\nThe special character problem can be addressed using parse_number instead of parse_double: it will ignore the special characters.\n\nparse_number(\"1.5€\")\n\n[1] 1.5\n\n\nThe final problem, grouping characters, can be addressed using another locale.\n\nparse_number(\"1.300.000\", locale = locale(grouping_mark = \".\"))\n\n[1] 1300000\n\n\n\n\n1.4.1.2 Date and time\nDate vectors in R are numeric vectors indicating how many days have passed since 1970. Date-Time vectors indicate the seconds that have passed since 1970-01-01 00:00:00. Time vectors indicate the number of seconds that have passed since midnight.\nThe parse_*() functions expect the vectors to be in a certain format:\n\nparse_datetime() expects the input to follow the ISO8601 standard. The times components must be ordered from biggest to smallest: year, month, day, hour, minute, second.\n\n\nparse_datetime(\"2000-02-29T2000\")\n\n[1] \"2000-02-29 20:00:00 UTC\"\n\n\n\nparse_date() wants a four digit year, two digit month, and two digit day. They can be separated by either “-” or “/”.\n\n\nparse_date(\"2000-02-29\")\n\n[1] \"2000-02-29\"\n\nparse_date(\"2000/02/29\")\n\n[1] \"2000-02-29\"\n\n\nDo you wonder why I chose 2000-02-29? It’s R’s birthday…\n\nparse_time() needs at least hours and minutes, seconds are optional. They need to be separated by colons. There is no proper built-in class for time data in Base R. Hence, I will use the hms package here.\n\n\nlibrary(hms)\nparse_time(\"20:15:00\")\n\n20:15:00\n\nparse_time(\"20:15\") # both works\n\n20:15:00\n\n\nWhen it comes to dates, you can also build your own format. Just mash together the following pieces:\n\nYear: %Y – year in 4 digits; %y – year in two digits following this rule: 00–69 = 2000–2069, 70–99 = 1970–1999\n\nMonth: %m – two digits; %b – abbreviated name (e.g., “Nov”); %B – full name (e.g., “November”)\n\nDay: %d – two digits\n\nTime: %H – hour, 0–23; %h – hour, 1–12, must come together with %p – a.m./p.m. indicator; %M – minutes; %S – integer seconds; %Z time zone – America/Chicago for instance\n\nNon-digits: %. skips one non-digit character; %* skips any number of non-digits\n\nYou might see that there can emerge problems with this. You might, for example, have something like this:\n\nexample_date <- \"29. Februar 2000\"\n\nSo how can you parse this date with a German month name? Again, you can use locale =.\n\ndate_names_langs() # what could be the proper abbreviation?\n\n  [1] \"af\"  \"agq\" \"ak\"  \"am\"  \"ar\"  \"as\"  \"asa\" \"az\"  \"bas\" \"be\"  \"bem\" \"bez\"\n [13] \"bg\"  \"bm\"  \"bn\"  \"bo\"  \"br\"  \"brx\" \"bs\"  \"ca\"  \"cgg\" \"chr\" \"cs\"  \"cy\" \n [25] \"da\"  \"dav\" \"de\"  \"dje\" \"dsb\" \"dua\" \"dyo\" \"dz\"  \"ebu\" \"ee\"  \"el\"  \"en\" \n [37] \"eo\"  \"es\"  \"et\"  \"eu\"  \"ewo\" \"fa\"  \"ff\"  \"fi\"  \"fil\" \"fo\"  \"fr\"  \"fur\"\n [49] \"fy\"  \"ga\"  \"gd\"  \"gl\"  \"gsw\" \"gu\"  \"guz\" \"gv\"  \"ha\"  \"haw\" \"he\"  \"hi\" \n [61] \"hr\"  \"hsb\" \"hu\"  \"hy\"  \"id\"  \"ig\"  \"ii\"  \"is\"  \"it\"  \"ja\"  \"jgo\" \"jmc\"\n [73] \"ka\"  \"kab\" \"kam\" \"kde\" \"kea\" \"khq\" \"ki\"  \"kk\"  \"kkj\" \"kl\"  \"kln\" \"km\" \n [85] \"kn\"  \"ko\"  \"kok\" \"ks\"  \"ksb\" \"ksf\" \"ksh\" \"kw\"  \"ky\"  \"lag\" \"lb\"  \"lg\" \n [97] \"lkt\" \"ln\"  \"lo\"  \"lt\"  \"lu\"  \"luo\" \"luy\" \"lv\"  \"mas\" \"mer\" \"mfe\" \"mg\" \n[109] \"mgh\" \"mgo\" \"mk\"  \"ml\"  \"mn\"  \"mr\"  \"ms\"  \"mt\"  \"mua\" \"my\"  \"naq\" \"nb\" \n[121] \"nd\"  \"ne\"  \"nl\"  \"nmg\" \"nn\"  \"nnh\" \"nus\" \"nyn\" \"om\"  \"or\"  \"os\"  \"pa\" \n[133] \"pl\"  \"ps\"  \"pt\"  \"qu\"  \"rm\"  \"rn\"  \"ro\"  \"rof\" \"ru\"  \"rw\"  \"rwk\" \"sah\"\n[145] \"saq\" \"sbp\" \"se\"  \"seh\" \"ses\" \"sg\"  \"shi\" \"si\"  \"sk\"  \"sl\"  \"smn\" \"sn\" \n[157] \"so\"  \"sq\"  \"sr\"  \"sv\"  \"sw\"  \"ta\"  \"te\"  \"teo\" \"th\"  \"ti\"  \"to\"  \"tr\" \n[169] \"twq\" \"tzm\" \"ug\"  \"uk\"  \"ur\"  \"uz\"  \"vai\" \"vi\"  \"vun\" \"wae\" \"xog\" \"yav\"\n[181] \"yi\"  \"yo\"  \"zgh\" \"zh\"  \"zu\" \n\nparse_date(example_date, format = \"%d%. %B %Y\", locale = locale(date_names = \"de\"))\n\n[1] \"2000-02-29\"\n\n\nNow you know how to parse number and date vectors yourself. This is nice, but normally you do not want to read in data, put it into character vectors and then parse it to the right data format. You want to read in a data set and get a Tibble whose columns consist of data which have been parsed to the right type already.\n\n\n1.4.1.3 Parsing entire files\nAs mentioned earlier, the read_* functions take the first 1000 rows and then guess the columns format. I emulated this using the guess_parser() function.\nIf readr finds values in a column that do not match the type of the column which it has guessed in first place, or entirely fails to parse a column (e.g., because it only consists of NAs), it returns parsing failures. They can be obtained using problems().\n\nchallenge <- read_csv(readr_example(\"challenge.csv\"))\n\nRows: 2000 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl  (1): x\ndate (1): y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(challenge)\n\n# A tibble: 6 × 2\n      x y     \n  <dbl> <date>\n1   404 NA    \n2  4172 NA    \n3  3004 NA    \n4   787 NA    \n5    37 NA    \n6  2332 NA    \n\nproblems(challenge)\n\n# A tibble: 0 × 5\n# … with 5 variables: row <int>, col <int>, expected <chr>, actual <chr>,\n#   file <chr>\n\n\nWhen looking at the parsing failures here, what catches the eye is that the first 1000 values of challenge$y seem to be NA. Because readr only takes the first 1000 rows into account, it parses challenge$y as logical. However, it should be considered a date column. You can specify this using col_types =:\n\nchallenge_w_date <- read_csv(readr_example(\"challenge.csv\"),\n                             col_types = cols(\n                               x = col_number(),\n                               y = col_date()\n                             ))\n\nIn general, every parse_* function has its col_* counterpart.\nIf you want to read in data and change the column specifications, there is a little shortcut:\nFirst, read in your data set:\n\nchallenge <- read_csv(readr_example(\"challenge.csv\"))\n\nRows: 2000 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl  (1): x\ndate (1): y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nSecond, you can copy the column specification from the output to your clipboard:\n\n#This part: \n#cols(\n#  x = col_double(),\n#  y = col_logical()\n#)\n\nThird, provide it your read_csv() call as a col_types = argument (by simply pasting it):\n\n#challenge <- read_csv(readr_example(\"challenge.csv\"),\n#                     col_types = cols(\n#                       x = col_double(),\n#  needs to be modified --> y = col_logical()\n#                            ))\n\nFourth, modify the argument:\n\n#challenge_w_date <- read_csv(readr_example(\"challenge.csv\"),\n#                             col_types = cols(\n#                               x = col_number(),\n#  modified -->                 y = col_date()\n#                            ))\n\nFifth, read it in:\n\nchallenge_w_date <- read_csv(readr_example(\"challenge.csv\"),\n                      col_types = cols(\n                        x = col_number(),\n                        y = col_date()\n                      ))"
  },
  {
    "objectID": "projects_readr.html#rds-and-.rdatafiles",
    "href": "projects_readr.html#rds-and-.rdatafiles",
    "title": "1  Introduction to RStudio Projects and readr",
    "section": "1.5 .rds and .RDatafiles",
    "text": "1.5 .rds and .RDatafiles\n.rds files can be used to store singular R-specific objects (such as lists), .RData files can be used to store multiple R-specific objects. The former can be read in using read_rds(\"file.rds\"), the latter with load(\"file.RData\"). More on read_rds() here and .RData here"
  },
  {
    "objectID": "projects_readr.html#write_csv",
    "href": "projects_readr.html#write_csv",
    "title": "1  Introduction to RStudio Projects and readr",
    "section": "2.1 write_csv()",
    "text": "2.1 write_csv()\nWriting data is fairly straight-forward. Most of the times, you will work with plain Tibbles which consist of different kinds of vectors except for lists. If you want to store them, I recommend you to simply use write_csv(tibble, path = \"file.csv\"). If you plan on working on the .csv file in Excel, use write_excel_csv(tibble, path = \"file.csv\")"
  },
  {
    "objectID": "projects_readr.html#write_rds",
    "href": "projects_readr.html#write_rds",
    "title": "1  Introduction to RStudio Projects and readr",
    "section": "2.2 write_rds()",
    "text": "2.2 write_rds()\nSometimes, however, it might be impossible to create a .csv file of your data – e.g., if you want to store a list. This is what you can use write_rds(r_specific_object, path = \"file.rds\") for."
  },
  {
    "objectID": "projects_readr.html#save",
    "href": "projects_readr.html#save",
    "title": "1  Introduction to RStudio Projects and readr",
    "section": "2.3 save()",
    "text": "2.3 save()\nAkin to .rds files are .RData files. They can contain multiple objects and be written using save(r_specific_object_1, r_specific_object_2, r_specific_object_n, file = \"file.RData\"). You can save your entire workspace as well by calling save.image(file = \"file.RData\")."
  },
  {
    "objectID": "projects_readr.html#alternative-ways-to-read-in-and-write-data",
    "href": "projects_readr.html#alternative-ways-to-read-in-and-write-data",
    "title": "1  Introduction to RStudio Projects and readr",
    "section": "2.4 Alternative ways to read in and write data",
    "text": "2.4 Alternative ways to read in and write data\nThere do also other packages exist for different data types. I will explain the ones which might be of particular use for you and their main-functions only briefly.\n\n2.4.1 haven\nYou can use haven (wickham2020c?) for reading and writing SAS (suffixes .sas7bdat, .sas7bcat, and .xpt), SPSS (suffixes .sav and .por), and STATA (suffix .dta) files.\nThe functions then are:\n\nread_sas(\"file.sas7bdate\" and write_sas(tibble, \"file.sas7bdat\") for both .sas7bdat and .sas7bcat files. read_xpt(\"file.xpt\") reads .xpt files\n\nread_sav(\"file.sav\") and read_por(\"file.por\") for .sav and .por files. write_sav(tibble, \"file.sav\" writes a the Tibble tibble to the file file.sav\n\nread_dta(\"file.dta\") and write_dta(tibble, \"file.dta\") read and write .dta files\n\nThe additional arguments can be found in the vignette.\n\n\n2.4.2 readxl\nreadxl (wickham2019e?) can be used to read Excel files. read_excel(\"file.xls\") works for both .xls and .xlsx files alike. It guesses the data type from the suffix. Excel files often consist of multiple sheets. excel_sheets(\"file.xlsx\") returns the name of the singular sheets. When dealing with an Excel file that contains multiple sheets, you need to specify the sheet you are after in the read_excel() function: read_excel(\"file.xlsx\", sheet = \"sheet_1\"). Please note that it only takes one sheet at a time.\nMore on the readxl package can be found here.\n\n\n2.4.3 vroom\nvroom has been introduced recently. It claims to be able to read in delimited files with up to 1.4 GB/s. Regarding its arguments, vroom works in the same way as the read_*() functions from the readr package. I would recommend you to use vroom as soon as your dataset’s size exceeds ~100 MB.\nMore on vroom here and here.\n\n\n2.4.4 Further readings\n\nInformation on working directories\n\nWebsites of the singular packages: readr, haven, readxl, vroom\n\nreadr Cheatsheet\n\nChapter in R for Data Science (wickham2016a?) regarding data import"
  },
  {
    "objectID": "dplyr.html",
    "href": "dplyr.html",
    "title": "3  Manipulation with dplyr",
    "section": "",
    "text": "The last chapter showed you four things: how you get data sets into R, a couple of ways to create tibbles, how to pass data to functions using the pipe (|>), and an introduction to tidy data and how to make data sets tidy using the tidyr package (wickham2020b?). What you haven’t learned was how you can actually manipulate the data itself. In the tidyverse framework (wickham2019d?), the package which enables you to accomplish those tasks is dplyr (wickham2020?).\ndplyr joined the party in 2014, building upon the plyr package. The d in dplyr stands for data set and dplyr works with tibbles (or data frames) only.\nIt consists of five main functions, the “verbs”:\nThey are joined by group_by(), a function that changes the scope on which entities the functions are applied to.\nFurthermore, diverse bind_ functions and _joins enable you to combine multiple tibbles into one. They will be introduced later."
  },
  {
    "objectID": "dplyr.html#working-with-the-main-verbs",
    "href": "dplyr.html#working-with-the-main-verbs",
    "title": "3  Manipulation with dplyr",
    "section": "3.1 Working with the main “verbs”",
    "text": "3.1 Working with the main “verbs”\nIn the following, I will guide you through how you can use the verbs to accomplish whatever goals which require data wrangling you might have.\nThe data set I will use here consists of the 1,000 most popular movies on IMDb which were published between 2006 and 2016 and some data on them. It was created by PromptCloud and DataStock and published on Kaggle, more information can be found here.\n\nlibrary(tidyverse)\n\nimdb_raw <- read_csv(\"https://www.dropbox.com/s/wfwyxjkpo24e3yq/imdb2006-2016.csv?dl=1\")\n\nThe data set hasn’t been modified by me before. I will show you how I would go across it using a couple of dplyr functions.\n\n3.1.1 select()\nselect enables you to select columns. Since we are dealing with tidy data, every variable has its own column.\nglimpse() provides you with an overview of the data set and its columns.\n\nglimpse(imdb_raw)\n\nRows: 1,000\nColumns: 12\n$ Rank                 <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15…\n$ Title                <chr> \"Guardians of the Galaxy\", \"Prometheus\", \"Split\",…\n$ Genre                <chr> \"Action,Adventure,Sci-Fi\", \"Adventure,Mystery,Sci…\n$ Description          <chr> \"A group of intergalactic criminals are forced to…\n$ Director             <chr> \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan…\n$ Actors               <chr> \"Chris Pratt, Vin Diesel, Bradley Cooper, Zoe Sal…\n$ Year                 <dbl> 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2…\n$ `Runtime (Minutes)`  <dbl> 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, …\n$ Rating               <dbl> 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0,…\n$ Votes                <dbl> 757074, 485820, 157606, 60545, 393727, 56036, 258…\n$ `Revenue (Millions)` <dbl> 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 15…\n$ Metascore            <dbl> 76, 65, 62, 59, 40, 42, 93, 71, 78, 41, 66, 74, 6…\n\n\nThe columns I want to keep are: Title, Director, Year, Runtime (Minutes), Rating, Votes, and Revenue (Millions). Furthermore, I want to rename the columns: every column’s name should be in lowercase and a regular name that does not need to be surrounded by back ticks – i.e., a name that only consists of characters, numbers, underscores, or dots.\nThis can be achieved in a couple of ways:\nFirst, by choosing the columns column by column and subsequently renaming them:\n\nimdb_raw |> \n  select(Title, Director, Year, `Runtime (Minutes)`, Rating, Votes, `Revenue (Millions)`) |> \n  rename(title = Title, director = Director, year = Year, runtime = `Runtime (Minutes)`, rating = Rating, votes = Votes, revenue_million = `Revenue (Millions)`) |> \n  glimpse()\n\nRows: 1,000\nColumns: 7\n$ title           <chr> \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        <chr> \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ year            <dbl> 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         <dbl> 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, …\n$ rating          <dbl> 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5,…\n$ votes           <dbl> 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ revenue_million <dbl> 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\nSecond, the columns can also be chosen vice versa: unnecessary columns can be dropped using a minus:\n\nimdb_raw |> \n  select(-Rank, -Genre, -Description, -Actors, -Metascore) |> \n  rename(title = Title, director = Director, year = Year, runtime = `Runtime (Minutes)`, rating = Rating, votes = Votes, revenue_million = `Revenue (Millions)`) |> \n  glimpse()\n\nRows: 1,000\nColumns: 7\n$ title           <chr> \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        <chr> \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ year            <dbl> 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         <dbl> 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, …\n$ rating          <dbl> 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5,…\n$ votes           <dbl> 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ revenue_million <dbl> 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\nColumns can also be renamed in the selecting process:\n\nimdb_raw |> \n  select(title = Title, director = Director, year = Year, runtime = `Runtime (Minutes)`, rating = Rating, votes = Votes, revenue_million = `Revenue (Millions)`) |> \n  glimpse()\n\nRows: 1,000\nColumns: 7\n$ title           <chr> \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        <chr> \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ year            <dbl> 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         <dbl> 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, …\n$ rating          <dbl> 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5,…\n$ votes           <dbl> 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ revenue_million <dbl> 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\nYou can also make your expressions shorter by using a couple of hacks:\n: can be used to select all columns between two:\n\nimdb_raw |> \n  select(Title, Director, Year:`Revenue (Millions)`) |> \n  rename(title = Title, director = Director, year = Year, runtime = `Runtime (Minutes)`, rating = Rating, votes = Votes, revenue_million = `Revenue (Millions)`) |> \n  glimpse()\n\nRows: 1,000\nColumns: 7\n$ title           <chr> \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        <chr> \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ year            <dbl> 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         <dbl> 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, …\n$ rating          <dbl> 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5,…\n$ votes           <dbl> 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ revenue_million <dbl> 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\nstarts_with() select columns whose names start with the same character string:\n\nimdb_selected <- imdb_raw |> \n  select(Title, Director, Votes, Year, starts_with(\"R\")) |> \n  select(-Rank) |> \n  rename(title = Title, director = Director, year = Year, runtime = `Runtime (Minutes)`, rating = Rating, votes = Votes, revenue_million = `Revenue (Millions)`) |> \n  glimpse()\n\nRows: 1,000\nColumns: 7\n$ title           <chr> \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        <chr> \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ votes           <dbl> 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ year            <dbl> 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         <dbl> 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, …\n$ rating          <dbl> 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5,…\n$ revenue_million <dbl> 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\nAs you may have noticed, the order in the select() matters: columns will be ordered in the same order as they are chosen.\nA couple of further shortcuts for select() do exist. An overview can be found in the dplyr cheatsheet.\n\n\n3.1.2 filter()\nWhereas select() enables you to choose variables (i.e., columns), filter() lets you choose observations (i.e., rows).\nIn this case, I only want movies with a revenue above $100,000,000:\n\nimdb_selected |> \n  filter(revenue_million > 100) |> \n  glimpse()\n\nRows: 250\nColumns: 7\n$ title           <chr> \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        <chr> \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ votes           <dbl> 757074, 485820, 157606, 60545, 393727, 258682, 192177,…\n$ year            <dbl> 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         <dbl> 121, 124, 117, 108, 123, 128, 116, 133, 127, 133, 107,…\n$ rating          <dbl> 8.1, 7.0, 7.3, 7.2, 6.2, 8.3, 7.0, 7.5, 7.8, 7.9, 7.7,…\n$ revenue_million <dbl> 333.13, 126.46, 138.12, 270.32, 325.02, 151.06, 100.01…\n\n\nBesides, I am especially interested in the director Christopher Nolan. Therefore, I want to look at movies that were directed by him and made more than $100,000,000:\n\nimdb_selected |> \n  filter(revenue_million > 100 & director == \"Christopher Nolan\") |> \n  glimpse()\n\nRows: 4\nColumns: 7\n$ title           <chr> \"Interstellar\", \"The Dark Knight\", \"Inception\", \"The D…\n$ director        <chr> \"Christopher Nolan\", \"Christopher Nolan\", \"Christopher…\n$ votes           <dbl> 1047747, 1791916, 1583625, 1222645\n$ year            <dbl> 2014, 2008, 2010, 2012\n$ runtime         <dbl> 169, 152, 148, 164\n$ rating          <dbl> 8.6, 9.0, 8.8, 8.5\n$ revenue_million <dbl> 187.99, 533.32, 292.57, 448.13\n\n\nThe following overview is taken from the dplyr cheatsheet and shows the operators you can use in filter():\n\n\n\nOverview of comparison operators\n\n\n\n3.1.2.1 Exemplary application\nTo demonstrate how a real-world application of this stuff could look like, I will now provide you a brief insight into my private life and how I organize movie nights. JK. You could definitely try this at home and surprise your loved ones with such hot applications. If you are brave and surprise your latest Tinder match with an .RDS file containing suggestions for Netflix&Chill, please let me know what their response looked like.\nTonight, I will hang out with a real nerd. Probably because they (nerds have all kinds of genders) know about my faible for R, they have sent me a vector containing a couple of movies we could watch tonight:\n\nset.seed(123) # guarantees that movie_vec will always be the same thing\nmovie_vec <- imdb_raw$Title[sample(1000, 10, replace = FALSE)]\nmovie_vec\n\n [1] \"Mechanic: Resurrection\" \"Denial\"                 \"The Conjuring 2\"       \n [4] \"Birth of the Dragon\"    \"Warrior\"                \"Super\"                 \n [7] \"127 Hours\"              \"Dangal\"                 \"The Infiltrator\"       \n[10] \"Maleficent\"            \n\n\nHowever, I want to make a more informed decision and decide to obtain some more information on the movies from my IMDb data set:\n\nimdb_selected |> \n  filter(title %in% movie_vec) |> \n  glimpse()\n\nRows: 10\nColumns: 7\n$ title           <chr> \"Dangal\", \"The Conjuring 2\", \"Warrior\", \"Maleficent\", …\n$ director        <chr> \"Nitesh Tiwari\", \"James Wan\", \"Gavin O'Connor\", \"Rober…\n$ votes           <dbl> 48969, 137203, 355722, 268877, 43929, 48161, 8229, 552…\n$ year            <dbl> 2016, 2016, 2011, 2014, 2016, 2016, 2016, 2016, 2010, …\n$ runtime         <dbl> 161, 134, 140, 97, 127, 98, 109, 103, 94, 96\n$ rating          <dbl> 8.8, 7.4, 8.2, 7.0, 7.1, 5.6, 6.6, 3.9, 7.6, 6.8\n$ revenue_million <dbl> 11.15, 102.46, 13.65, 241.41, 15.43, 21.20, 4.07, 93.0…\n\n\nI have convinced them to watch either one of the movies they have suggested or one directed by Christopher Nolan or one with a rating greater or equal to 8.5 and send them back this data set:\n\nimdb_selected |> \n  filter(title %in% movie_vec | director == \"Christopher Nolan\" | rating >= 8.5) |> \n  glimpse()\n\nRows: 21\nColumns: 7\n$ title           <chr> \"Interstellar\", \"The Dark Knight\", \"The Prestige\", \"In…\n$ director        <chr> \"Christopher Nolan\", \"Christopher Nolan\", \"Christopher…\n$ votes           <dbl> 1047747, 1791916, 913152, 1583625, 34110, 937414, 4896…\n$ year            <dbl> 2014, 2008, 2006, 2010, 2016, 2006, 2016, 2012, 2014, …\n$ runtime         <dbl> 169, 152, 130, 148, 106, 151, 161, 164, 107, 134, 140,…\n$ rating          <dbl> 8.6, 9.0, 8.5, 8.8, 8.6, 8.5, 8.8, 8.5, 8.5, 7.4, 8.2,…\n$ revenue_million <dbl> 187.99, 533.32, 53.08, 292.57, 4.68, 132.37, 11.15, 44…\n\n\n“I deteste ‘Interstellar’,” is the response. “All right,” I say to myself, “I can easily exclude it.”\n\nimdb_selected |> \n  filter(title %in% movie_vec | director == \"Christopher Nolan\" | rating >= 8.5 & title != \"Interstellar\") |> # if you want to negate something, put the ! in front of it\n  glimpse()\n\nRows: 21\nColumns: 7\n$ title           <chr> \"Interstellar\", \"The Dark Knight\", \"The Prestige\", \"In…\n$ director        <chr> \"Christopher Nolan\", \"Christopher Nolan\", \"Christopher…\n$ votes           <dbl> 1047747, 1791916, 913152, 1583625, 34110, 937414, 4896…\n$ year            <dbl> 2014, 2008, 2006, 2010, 2016, 2006, 2016, 2012, 2014, …\n$ runtime         <dbl> 169, 152, 130, 148, 106, 151, 161, 164, 107, 134, 140,…\n$ rating          <dbl> 8.6, 9.0, 8.5, 8.8, 8.6, 8.5, 8.8, 8.5, 8.5, 7.4, 8.2,…\n$ revenue_million <dbl> 187.99, 533.32, 53.08, 292.57, 4.68, 132.37, 11.15, 44…\n\n\nOh, that did not work. I should wrap them in columns:\n\nimdb_selected |> \n  filter((title %in% movie_vec | director == \"Christopher Nolan\" | rating >= 8.5) & title != \"Interstellar\") |> \n  glimpse()\n\nRows: 20\nColumns: 7\n$ title           <chr> \"The Dark Knight\", \"The Prestige\", \"Inception\", \"Kimi …\n$ director        <chr> \"Christopher Nolan\", \"Christopher Nolan\", \"Christopher…\n$ votes           <dbl> 1791916, 913152, 1583625, 34110, 937414, 48969, 122264…\n$ year            <dbl> 2008, 2006, 2010, 2016, 2006, 2016, 2012, 2014, 2016, …\n$ runtime         <dbl> 152, 130, 148, 106, 151, 161, 164, 107, 134, 140, 97, …\n$ rating          <dbl> 9.0, 8.5, 8.8, 8.6, 8.5, 8.8, 8.5, 8.5, 7.4, 8.2, 7.0,…\n$ revenue_million <dbl> 533.32, 53.08, 292.57, 4.68, 132.37, 11.15, 448.13, 13…\n\n\nThey come up with a new idea: we have a Scottish evening with a movie directed by the Scottish director Gillies MacKinnon:\n\nimdb_selected |> \n  filter(director == \"Gillies MacKinnon\") |> \n  glimpse()\n\nRows: 1\nColumns: 7\n$ title           <chr> \"Whisky Galore\"\n$ director        <chr> \"Gillies MacKinnon\"\n$ votes           <dbl> 102\n$ year            <dbl> 2016\n$ runtime         <dbl> 98\n$ rating          <dbl> 5\n$ revenue_million <dbl> NA\n\n\n“Well, apparently there is a problem in the data set,” I notice. “There is an NA in the revenue column. I should probably have a further look at this.”\n\nimdb_selected |> \n  filter(is.na(revenue_million)) |> \n  glimpse()\n\nRows: 128\nColumns: 7\n$ title           <chr> \"Mindhorn\", \"Hounds of Love\", \"Paris pieds nus\", \"5- 2…\n$ director        <chr> \"Sean Foley\", \"Ben Young\", \"Dominique Abel\", \"Patrick …\n$ votes           <dbl> 2490, 1115, 222, 241, 496, 5103, 987, 35870, 149791, 7…\n$ year            <dbl> 2016, 2016, 2016, 2007, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         <dbl> 89, 108, 83, 113, 73, 91, 130, 86, 133, 106, 105, 118,…\n$ rating          <dbl> 6.4, 6.7, 6.8, 7.1, 2.7, 5.6, 3.7, 6.8, 5.9, 7.9, 5.8,…\n$ revenue_million <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\nWell, that’s quite a significant number of NAs. I will need to exclude these cases:\n\nimdb_selected |> \n  filter(!is.na(revenue_million)) |> \n  glimpse()\n\nRows: 872\nColumns: 7\n$ title           <chr> \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        <chr> \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ votes           <dbl> 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ year            <dbl> 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         <dbl> 121, 124, 117, 108, 123, 103, 128, 141, 116, 133, 127,…\n$ rating          <dbl> 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 7.1, 7.0, 7.5, 7.8,…\n$ revenue_million <dbl> 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\n\n\n3.1.2.2 Other possibilities to subset observations\nslice() selects rows by positions:\n\nimdb_selected |> \n  slice(1:10) |> \n  glimpse()\n\nRows: 10\nColumns: 7\n$ title           <chr> \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        <chr> \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ votes           <dbl> 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ year            <dbl> 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         <dbl> 121, 124, 117, 108, 123, 103, 128, 89, 141, 116\n$ rating          <dbl> 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0\n$ revenue_million <dbl> 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\ndistinct removes duplicate rows:\n\nimdb_selected |> \n  distinct(director) |> \n  glimpse()\n\nRows: 644\nColumns: 1\n$ director <chr> \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"Christop…\n\n\nBy default, it will remove all other columns apart from the one(s) you have specified. You can avoid that by setting .keep_all = TRUE:\n\nimdb_selected |> \n  distinct(title, .keep_all = TRUE) |> \n  glimpse()\n\nRows: 999\nColumns: 7\n$ title           <chr> \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        <chr> \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ votes           <dbl> 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ year            <dbl> 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         <dbl> 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, …\n$ rating          <dbl> 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5,…\n$ revenue_million <dbl> 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n\n\nOh, interesting, there is apparently one movie which is in there twice. How could we find this movie?\n\n\n\n3.1.3 mutate()\nMy data set looks pretty nice already, but one flaw catches the eye: the column revenue_million should probably be converted to revenue. Hence, I need to create a new variable which contains the values from revenue_million multiplied by 1,000,000 and drop the now obsolete revenue_million.\n\nimdb_selected |> \n  mutate(revenue = revenue_million * 1000000) |> \n  select(-revenue_million) |> \n  glimpse()\n\nRows: 1,000\nColumns: 7\n$ title    <chr> \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sing\", \"Su…\n$ director <chr> \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"Christop…\n$ votes    <dbl> 757074, 485820, 157606, 60545, 393727, 56036, 258682, 2490, 7…\n$ year     <dbl> 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2…\n$ runtime  <dbl> 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, 127, 13…\n$ rating   <dbl> 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5, 7.8, 7…\n$ revenue  <dbl> 333130000, 126460000, 138120000, 270320000, 325020000, 451300…\n\n\nThe structure of the mutate() call looks like this: first, you need to provide the name of the new variable. If the variable exists already, it will be replaced. Second, the equal sign tells R what the new variable should contain. Third, a function that outputs a vector which is as long as the tibble has rows or 1.\nIf we want to drop all other columns and just keep the new one: transmute() drops all the original columns.\n\nimdb_selected |> \n  transmute(revenue = revenue_million * 1000000) |> \n  glimpse()\n\nRows: 1,000\nColumns: 1\n$ revenue <dbl> 333130000, 126460000, 138120000, 270320000, 325020000, 4513000…\n\n\nmutate() uses so-called window functions. They take one vector of values and return another vector of values. An overview – again, from the cheat sheet:\n\n\n\nWindow functions\n\n\nAnother feature of dplyr, which is useful in combination with mutate(), is case_when().\ncase_when() can for instance be used to create binary indicator variables. In this example I want it to be 0 if the movie was made before 2010 and 1 if not.\n\nimdb_selected |> \n  mutate(indicator = case_when(year < 2010 ~ 0,\n                               year >= 2010 ~ 1,\n                               TRUE ~ 2)) |> \n  glimpse()\n\nRows: 1,000\nColumns: 8\n$ title           <chr> \"Guardians of the Galaxy\", \"Prometheus\", \"Split\", \"Sin…\n$ director        <chr> \"James Gunn\", \"Ridley Scott\", \"M. Night Shyamalan\", \"C…\n$ votes           <dbl> 757074, 485820, 157606, 60545, 393727, 56036, 258682, …\n$ year            <dbl> 2014, 2012, 2016, 2016, 2016, 2016, 2016, 2016, 2016, …\n$ runtime         <dbl> 121, 124, 117, 108, 123, 103, 128, 89, 141, 116, 133, …\n$ rating          <dbl> 8.1, 7.0, 7.3, 7.2, 6.2, 6.1, 8.3, 6.4, 7.1, 7.0, 7.5,…\n$ revenue_million <dbl> 333.13, 126.46, 138.12, 270.32, 325.02, 45.13, 151.06,…\n$ indicator       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n\n\nKeep in mind that you can throw any function into mutate() as long as it is vectorized and the output has the same length as the tibble or 1.\n\n\n3.1.4 summarize() and group_by\nWhen you analyze data, you often want to compare entities according to some sort of summary statistic. This means that you, first, need to split up your data set into certain groups which share one or more characteristics, and, second, collapse the columns together into single-row summaries. The former challenge is accomplished using group_by() whose argument is one or more variables, the latter requires the summarize() function. This function works similar to mutate() but uses summary functions – which take a vector of multiple values and return a single value – instead of window functions – which return a vector of the same length as the input.\nLet me provide you an example.\nI am interested in the director’s average ratings:\n\nimdb_selected |> \n  group_by(director) |> \n  summarize(avg_rating = mean(rating))\n\n# A tibble: 644 × 2\n   director            avg_rating\n   <chr>                    <dbl>\n 1 Aamir Khan                 8.5\n 2 Abdellatif Kechiche        7.8\n 3 Adam Leon                  6.5\n 4 Adam McKay                 7  \n 5 Adam Shankman              6.3\n 6 Adam Wingard               5.9\n 7 Afonso Poyart              6.4\n 8 Aisling Walsh              7.8\n 9 Akan Satayev               6.3\n10 Akiva Schaffer             6.7\n# … with 634 more rows\n\n\nIn general, summarize() always works like this: first, you change the scope from the entire tibble to different groups. Then, you calculate your summary. If you then want to further manipulate your date or calculate something else based on the new summary, you need to call ungroup().\nYou can see the summary functions below:\n\n\n\nSummary functions in R\n\n\nAnother handy function akin to this is count(). It counts all occurrences of a singular value in the tibble.\nIf I were interested in how many movies of the different directors have made it into the data set, I could use this code:\n\nimdb_selected |> \n  count(director)\n\n# A tibble: 644 × 2\n   director                n\n   <chr>               <int>\n 1 Aamir Khan              1\n 2 Abdellatif Kechiche     1\n 3 Adam Leon               1\n 4 Adam McKay              4\n 5 Adam Shankman           2\n 6 Adam Wingard            2\n 7 Afonso Poyart           1\n 8 Aisling Walsh           1\n 9 Akan Satayev            1\n10 Akiva Schaffer          1\n# … with 634 more rows\n\n\nBeyond that, you can also use group_by() with mutate. If you do so, the rows will not be collapsed together as in summarize().\n\n\n3.1.5 arrange()\nFinally, you can also sort values using arrange(). In the last section, I was interested in directors’ respective average ratings. The values were ordered according to their name (hence, “Aamir Khan” was first). In this case, the order dos not make too much sense, because the first name does not say too much about the director’s ratings. Therefore, I want to sort them according to their average ratings:\n\nimdb_selected |> \n  group_by(director) |> \n  summarize(avg_rating = mean(rating)) |> \n  arrange(avg_rating)\n\n# A tibble: 644 × 2\n   director           avg_rating\n   <chr>                   <dbl>\n 1 Jason Friedberg           1.9\n 2 James Wong                2.7\n 3 Shawn Burkett             2.7\n 4 Jonathan Holbrook         3.2\n 5 Femi Oyeniran             3.5\n 6 Micheal Bafaro            3.5\n 7 Jeffrey G. Hunt           3.7\n 8 Rolfe Kanefsky            3.9\n 9 Joey Curtis               4  \n10 Sam Taylor-Johnson        4.1\n# … with 634 more rows\n\n\nAll right, Jason Friedberg is apparently the director of the worst rated movie in my data set. But it would be more handy, if they were arranged in descending order. I can use desc() for this:\n\nimdb_selected |> \n  group_by(director) |> \n  summarize(avg_rating = mean(rating)) |> \n  arrange(-avg_rating)\n\n# A tibble: 644 × 2\n   director                         avg_rating\n   <chr>                                 <dbl>\n 1 Nitesh Tiwari                          8.8 \n 2 Christopher Nolan                      8.68\n 3 Makoto Shinkai                         8.6 \n 4 Olivier Nakache                        8.6 \n 5 Aamir Khan                             8.5 \n 6 Florian Henckel von Donnersmarck       8.5 \n 7 Damien Chazelle                        8.4 \n 8 Naoko Yamada                           8.4 \n 9 Amber Tamblyn                          8.3 \n10 Lee Unkrich                            8.3 \n# … with 634 more rows\n\n\nChapeau, Nitesh Tiwari!"
  },
  {
    "objectID": "dplyr.html#introducing-joins",
    "href": "dplyr.html#introducing-joins",
    "title": "3  Manipulation with dplyr",
    "section": "3.2 Introducing joins",
    "text": "3.2 Introducing joins\nThe last session showed you three things: how you get data sets into R, a couple of ways to create tibbles, and an introduction to tidy data and how to make data sets tidy using the tidyr package. As you may recall from the last session, it was not able to solve the last two problems with only the tools tidyr offers. In particular, the problems were:\n\nMultiple types of observational units are stored in the same table.\nA single observational unit is stored in multiple tables.\n\nBoth problems need some different kind of tools: joins. Joins can be used to merge tibbles together. This tutorial, again, builds heavy on the R for Data Science book (wickham2016a?)\n\n3.2.1 Multiple types of units are in the same table\nLet’s look at the following data set. It contains the billboard charts in 2000 and was obtained from the tidyr GitHub repo. The example below is taken from the tidyr vignette which can be loaded using vignette(\"tidy-data\", package = \"tidyr\").\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nbillboard <- read_csv(\"https://www.dropbox.com/s/e5gbrpa1fsrtvj5/billboard.csv?dl=1\")\n\nRows: 317 Columns: 79\n\n\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (2): artist, track\ndbl  (65): wk1, wk2, wk3, wk4, wk5, wk6, wk7, wk8, wk9, wk10, wk11, wk12, wk...\nlgl  (11): wk66, wk67, wk68, wk69, wk70, wk71, wk72, wk73, wk74, wk75, wk76\ndate  (1): date.entered\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(billboard)\n\nRows: 317\nColumns: 79\n$ artist       <chr> \"2 Pac\", \"2Ge+her\", \"3 Doors Down\", \"3 Doors Down\", \"504 …\n$ track        <chr> \"Baby Don't Cry (Keep...\", \"The Hardest Part Of ...\", \"Kr…\n$ date.entered <date> 2000-02-26, 2000-09-02, 2000-04-08, 2000-10-21, 2000-04-…\n$ wk1          <dbl> 87, 91, 81, 76, 57, 51, 97, 84, 59, 76, 84, 57, 50, 71, 7…\n$ wk2          <dbl> 82, 87, 70, 76, 34, 39, 97, 62, 53, 76, 84, 47, 39, 51, 6…\n$ wk3          <dbl> 72, 92, 68, 72, 25, 34, 96, 51, 38, 74, 75, 45, 30, 28, 5…\n$ wk4          <dbl> 77, NA, 67, 69, 17, 26, 95, 41, 28, 69, 73, 29, 28, 18, 4…\n$ wk5          <dbl> 87, NA, 66, 67, 17, 26, 100, 38, 21, 68, 73, 23, 21, 13, …\n$ wk6          <dbl> 94, NA, 57, 65, 31, 19, NA, 35, 18, 67, 69, 18, 19, 13, 3…\n$ wk7          <dbl> 99, NA, 54, 55, 36, 2, NA, 35, 16, 61, 68, 11, 20, 11, 34…\n$ wk8          <dbl> NA, NA, 53, 59, 49, 2, NA, 38, 14, 58, 65, 9, 17, 1, 29, …\n$ wk9          <dbl> NA, NA, 51, 62, 53, 3, NA, 38, 12, 57, 73, 9, 17, 1, 27, …\n$ wk10         <dbl> NA, NA, 51, 61, 57, 6, NA, 36, 10, 59, 83, 11, 17, 2, 30,…\n$ wk11         <dbl> NA, NA, 51, 61, 64, 7, NA, 37, 9, 66, 92, 1, 17, 2, 36, N…\n$ wk12         <dbl> NA, NA, 51, 59, 70, 22, NA, 37, 8, 68, NA, 1, 3, 3, 37, N…\n$ wk13         <dbl> NA, NA, 47, 61, 75, 29, NA, 38, 6, 61, NA, 1, 3, 3, 39, N…\n$ wk14         <dbl> NA, NA, 44, 66, 76, 36, NA, 49, 1, 67, NA, 1, 7, 4, 49, N…\n$ wk15         <dbl> NA, NA, 38, 72, 78, 47, NA, 61, 2, 59, NA, 4, 10, 12, 57,…\n$ wk16         <dbl> NA, NA, 28, 76, 85, 67, NA, 63, 2, 63, NA, 8, 17, 11, 63,…\n$ wk17         <dbl> NA, NA, 22, 75, 92, 66, NA, 62, 2, 67, NA, 12, 25, 13, 65…\n$ wk18         <dbl> NA, NA, 18, 67, 96, 84, NA, 67, 2, 71, NA, 22, 29, 15, 68…\n$ wk19         <dbl> NA, NA, 18, 73, NA, 93, NA, 83, 3, 79, NA, 23, 29, 18, 79…\n$ wk20         <dbl> NA, NA, 14, 70, NA, 94, NA, 86, 4, 89, NA, 43, 40, 20, 86…\n$ wk21         <dbl> NA, NA, 12, NA, NA, NA, NA, NA, 5, NA, NA, 44, 43, 30, NA…\n$ wk22         <dbl> NA, NA, 7, NA, NA, NA, NA, NA, 5, NA, NA, NA, 50, 40, NA,…\n$ wk23         <dbl> NA, NA, 6, NA, NA, NA, NA, NA, 6, NA, NA, NA, NA, 39, NA,…\n$ wk24         <dbl> NA, NA, 6, NA, NA, NA, NA, NA, 9, NA, NA, NA, NA, 44, NA,…\n$ wk25         <dbl> NA, NA, 6, NA, NA, NA, NA, NA, 13, NA, NA, NA, NA, NA, NA…\n$ wk26         <dbl> NA, NA, 5, NA, NA, NA, NA, NA, 14, NA, NA, NA, NA, NA, NA…\n$ wk27         <dbl> NA, NA, 5, NA, NA, NA, NA, NA, 16, NA, NA, NA, NA, NA, NA…\n$ wk28         <dbl> NA, NA, 4, NA, NA, NA, NA, NA, 23, NA, NA, NA, NA, NA, NA…\n$ wk29         <dbl> NA, NA, 4, NA, NA, NA, NA, NA, 22, NA, NA, NA, NA, NA, NA…\n$ wk30         <dbl> NA, NA, 4, NA, NA, NA, NA, NA, 33, NA, NA, NA, NA, NA, NA…\n$ wk31         <dbl> NA, NA, 4, NA, NA, NA, NA, NA, 36, NA, NA, NA, NA, NA, NA…\n$ wk32         <dbl> NA, NA, 3, NA, NA, NA, NA, NA, 43, NA, NA, NA, NA, NA, NA…\n$ wk33         <dbl> NA, NA, 3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk34         <dbl> NA, NA, 3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk35         <dbl> NA, NA, 4, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk36         <dbl> NA, NA, 5, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk37         <dbl> NA, NA, 5, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk38         <dbl> NA, NA, 9, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk39         <dbl> NA, NA, 9, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wk40         <dbl> NA, NA, 15, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk41         <dbl> NA, NA, 14, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk42         <dbl> NA, NA, 13, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk43         <dbl> NA, NA, 14, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk44         <dbl> NA, NA, 16, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk45         <dbl> NA, NA, 17, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk46         <dbl> NA, NA, 21, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk47         <dbl> NA, NA, 22, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk48         <dbl> NA, NA, 24, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk49         <dbl> NA, NA, 28, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk50         <dbl> NA, NA, 33, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk51         <dbl> NA, NA, 42, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk52         <dbl> NA, NA, 42, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk53         <dbl> NA, NA, 49, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk54         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk55         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk56         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk57         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk58         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk59         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk60         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk61         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk62         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk63         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk64         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk65         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk66         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk67         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk68         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk69         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk70         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk71         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk72         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk73         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk74         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk75         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ wk76         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n\nHere, you can immediately see the problem: it contains two types of observations: songs and ranks. Hence, the data set needs to be split up. However, there should be a pointer from the rank data set to the song data set. First, I add an ID column to song_tbl. Then, I can add it to rank_tbl and drop the unnecessary columns which contain the name of the artist and the track.\n\nsong_tbl <- billboard |> \n  distinct(artist, track) |> \n  mutate(song_id = row_number())\n\nglimpse(song_tbl)\n\nRows: 317\nColumns: 3\n$ artist  <chr> \"2 Pac\", \"2Ge+her\", \"3 Doors Down\", \"3 Doors Down\", \"504 Boyz\"…\n$ track   <chr> \"Baby Don't Cry (Keep...\", \"The Hardest Part Of ...\", \"Krypton…\n$ song_id <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,…\n\n\n\nrank_tbl <- billboard |> \n  pivot_longer(cols = starts_with(\"wk\"), \n               names_to = \"week\", \n               names_prefix = \"wk\", \n               values_to = \"rank\") |> \n  mutate(week = as.numeric(week),\n         date = date.entered + (week-1) * 7) |> \n  drop_na() |> \n  left_join(song_tbl, by = c(\"artist\", \"track\")) |> \n  select(song_id, date, week, rank)\n\nglimpse(rank_tbl)\n\nRows: 5,307\nColumns: 4\n$ song_id <int> 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,…\n$ date    <date> 2000-02-26, 2000-03-04, 2000-03-11, 2000-03-18, 2000-03-25, 2…\n$ week    <dbl> 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1…\n$ rank    <dbl> 87, 82, 72, 77, 87, 94, 99, 91, 87, 92, 81, 70, 68, 67, 66, 57…\n\n\n\n\n3.2.2 One unit is in multiple tables\nFor this example, I have split up a data set from the socviz package containing data on the 2016 elections in the U.S. according to census region and stored them in a folder. I can scrape the file names in the folder and read it into a list in an automated manner. (Note that the funtions used to read the files in in an automated fashion are beyond the scope of this course. They come from the fs and the purrr package.)1\n\nlibrary(fs)\nfile_list <- dir_ls(path = \"data/socviz_us\") |> \n  map(read_csv,\n      col_types = cols(\n        id = col_double(),\n        name = col_character(),\n        state = col_character(),\n        census_region = col_character(),\n        pop_dens = col_character(),\n        pop_dens4 = col_character(),\n        pop_dens6 = col_character(),\n        pct_black = col_character(),\n        pop = col_double(),\n        female = col_double(),\n        white = col_double(),\n        black = col_double(),\n        travel_time = col_double(),\n        land_area = col_double(),\n        hh_income = col_double(),\n        su_gun4 = col_character(),\n        su_gun6 = col_character(),\n        fips = col_double(),\n        votes_dem_2016 = col_double(),\n        votes_gop_2016 = col_double(),\n        total_votes_2016 = col_double(),\n        per_dem_2016 = col_double(),\n        per_gop_2016 = col_double(),\n        diff_2016 = col_double(),\n        per_dem_2012 = col_double(),\n        per_gop_2012 = col_double(),\n        diff_2012 = col_double(),\n        winner = col_character(),\n        partywinner16 = col_character(),\n        winner12 = col_character(),\n        partywinner12 = col_character(),\n        flipped = col_character()\n))\n\nThe list now consists of four tibbles which need to be bound together. You can achieve this using bind_rows(). Its counterpart is bind_cols() which binds columns together. It matches rows by position.\n\nelection_data <- file_list |> bind_rows()\nglimpse(election_data)\n\nRows: 3,141\nColumns: 32\n$ id               <dbl> 17001, 17003, 17005, 17007, 17009, 17011, 17013, 1701…\n$ name             <chr> \"Adams County\", \"Alexander County\", \"Bond County\", \"B…\n$ state            <chr> \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\", \"IL\",…\n$ census_region    <chr> \"Midwest\", \"Midwest\", \"Midwest\", \"Midwest\", \"Midwest\"…\n$ pop_dens         <chr> \"[   50,  100)\", \"[   10,   50)\", \"[   10,   50)\", \"[…\n$ pop_dens4        <chr> \"[ 45,  118)\", \"[ 17,   45)\", \"[ 45,  118)\", \"[118,71…\n$ pop_dens6        <chr> \"[ 45,   82)\", \"[ 25,   45)\", \"[ 45,   82)\", \"[ 82,  …\n$ pct_black        <chr> \"[ 2.0, 5.0)\", \"[25.0,50.0)\", \"[ 5.0,10.0)\", \"[ 2.0, …\n$ pop              <dbl> 66988, 7492, 17269, 53869, 6832, 33840, 4956, 14715, …\n$ female           <dbl> 51.3, 49.5, 47.5, 50.2, 35.5, 51.0, 49.7, 50.1, 49.1,…\n$ white            <dbl> 93.7, 60.6, 90.9, 93.2, 78.6, 96.8, 98.8, 96.7, 93.2,…\n$ black            <dbl> 3.7, 36.1, 6.5, 2.6, 19.1, 0.8, 0.3, 1.1, 4.4, 12.8, …\n$ travel_time      <dbl> 16.6, 25.6, 23.6, 30.1, 18.9, 20.4, 39.6, 23.8, 22.2,…\n$ land_area        <dbl> 855.20, 235.51, 380.28, 280.72, 305.61, 869.03, 253.8…\n$ hh_income        <dbl> 45073, 26972, 48163, 60893, 42194, 48977, 50436, 4798…\n$ su_gun4          <chr> \"[ 0, 5)\", \"[ 5, 8)\", \"[ 0, 5)\", \"[ 0, 5)\", \"[ 0, 5)\"…\n$ su_gun6          <chr> \"[ 4, 7)\", \"[ 7, 8)\", \"[ 4, 7)\", \"[ 0, 4)\", \"[ 0, 4)\"…\n$ fips             <dbl> 17001, 17003, 17005, 17007, 17009, 17011, 17013, 1701…\n$ votes_dem_2016   <dbl> 7633, 1262, 2066, 8952, 475, 6010, 739, 2437, 1617, 4…\n$ votes_gop_2016   <dbl> 22732, 1496, 4884, 12261, 1776, 9264, 1719, 4428, 321…\n$ total_votes_2016 <dbl> 31770, 2820, 7462, 22604, 2336, 16303, 2556, 7354, 50…\n$ per_dem_2016     <dbl> 0.2402581, 0.4475177, 0.2768695, 0.3960361, 0.2033390…\n$ per_gop_2016     <dbl> 0.7155178, 0.5304965, 0.6545162, 0.5424261, 0.7602740…\n$ diff_2016        <dbl> 15099, 234, 2818, 3309, 1301, 3254, 980, 1991, 1599, …\n$ per_dem_2012     <dbl> 0.3152466, 0.5610873, 0.4122471, 0.4625697, 0.3331922…\n$ per_gop_2012     <dbl> 0.6670705, 0.4248927, 0.5591853, 0.5195706, 0.6397121…\n$ diff_2012        <dbl> 10744, 476, 1075, 1216, 724, 33, 360, 107, 657, 5292,…\n$ winner           <chr> \"Trump\", \"Trump\", \"Trump\", \"Trump\", \"Trump\", \"Trump\",…\n$ partywinner16    <chr> \"Republican\", \"Republican\", \"Republican\", \"Republican…\n$ winner12         <chr> \"Romney\", \"Obama\", \"Romney\", \"Romney\", \"Romney\", \"Rom…\n$ partywinner12    <chr> \"Republican\", \"Democrat\", \"Republican\", \"Republican\",…\n$ flipped          <chr> \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No…\n\n\nNow, the data set is ready for cleaning and tidying. Feel free to do this is as a take-home exercise.\nHowever, the topic of this script is different joins. The dplyr package offers six different joins: left_join(), right_join(), inner_join(), full_join(), semi_join(), and anti_join(). The former four are mutating joins, they add columns. The latter two can be used to filter rows in a data set. Below is an overview from the dplyr cheat sheet:\n\n\n\nOverview of the different joins\n\n\nIn the following, I will illustrate this using the election data. I split up the data set into three: data on the elections 2016 and 2012, and demographic data. The column they have in common is the county’s respective name.\n\nelection_data16 <- election_data |> \n  select(name, state, votes_dem_2016:diff_2016, winner, partywinner16)\n\nelection_data12 <- election_data |> \n  select(name, state, per_dem_2012:partywinner12)\n\ndemographic_data <- election_data |> \n  select(name, state, pop:hh_income) |> \n  slice(1:2000)\n\n\n\n3.2.3 left_join() and right_join()\n\nelection_data16 |> \n  left_join(demographic_data)\n\nJoining, by = c(\"name\", \"state\")\n\n\n# A tibble: 3,141 × 17\n   name     state votes…¹ votes…² total…³ per_d…⁴ per_g…⁵ diff_…⁶ winner party…⁷\n   <chr>    <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>  <chr>  \n 1 Adams C… IL       7633   22732   31770   0.240   0.716   15099 Trump  Republ…\n 2 Alexand… IL       1262    1496    2820   0.448   0.530     234 Trump  Republ…\n 3 Bond Co… IL       2066    4884    7462   0.277   0.655    2818 Trump  Republ…\n 4 Boone C… IL       8952   12261   22604   0.396   0.542    3309 Trump  Republ…\n 5 Brown C… IL        475    1776    2336   0.203   0.760    1301 Trump  Republ…\n 6 Bureau … IL       6010    9264   16303   0.369   0.568    3254 Trump  Republ…\n 7 Calhoun… IL        739    1719    2556   0.289   0.673     980 Trump  Republ…\n 8 Carroll… IL       2437    4428    7354   0.331   0.602    1991 Trump  Republ…\n 9 Cass Co… IL       1617    3216    5054   0.320   0.636    1599 Trump  Republ…\n10 Champai… IL      49694   33235   89196   0.557   0.373   16459 Clint… Democr…\n# … with 3,131 more rows, 7 more variables: pop <dbl>, female <dbl>,\n#   white <dbl>, black <dbl>, travel_time <dbl>, land_area <dbl>,\n#   hh_income <dbl>, and abbreviated variable names ¹​votes_dem_2016,\n#   ²​votes_gop_2016, ³​total_votes_2016, ⁴​per_dem_2016, ⁵​per_gop_2016,\n#   ⁶​diff_2016, ⁷​partywinner16\n\n\nIf the column that both data sets have in common has the same name, there’s no need to provide it. If this is not the case, you need to provide it in a character vector:\n\nelection_data16 |> \n  rename(county = name) |> \n  right_join(demographic_data, by = c(\"county\" = \"name\"))\n\n# A tibble: 10,348 × 18\n   county state.x votes…¹ votes…² total…³ per_d…⁴ per_g…⁵ diff_…⁶ winner party…⁷\n   <chr>  <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>  <chr>  \n 1 Adams… IL         7633   22732   31770   0.240   0.716   15099 Trump  Republ…\n 2 Adams… IL         7633   22732   31770   0.240   0.716   15099 Trump  Republ…\n 3 Adams… IL         7633   22732   31770   0.240   0.716   15099 Trump  Republ…\n 4 Adams… IL         7633   22732   31770   0.240   0.716   15099 Trump  Republ…\n 5 Adams… IL         7633   22732   31770   0.240   0.716   15099 Trump  Republ…\n 6 Adams… IL         7633   22732   31770   0.240   0.716   15099 Trump  Republ…\n 7 Adams… IL         7633   22732   31770   0.240   0.716   15099 Trump  Republ…\n 8 Adams… IL         7633   22732   31770   0.240   0.716   15099 Trump  Republ…\n 9 Adams… IL         7633   22732   31770   0.240   0.716   15099 Trump  Republ…\n10 Alexa… IL         1262    1496    2820   0.448   0.530     234 Trump  Republ…\n# … with 10,338 more rows, 8 more variables: state.y <chr>, pop <dbl>,\n#   female <dbl>, white <dbl>, black <dbl>, travel_time <dbl>, land_area <dbl>,\n#   hh_income <dbl>, and abbreviated variable names ¹​votes_dem_2016,\n#   ²​votes_gop_2016, ³​total_votes_2016, ⁴​per_dem_2016, ⁵​per_gop_2016,\n#   ⁶​diff_2016, ⁷​partywinner16\n\n\nHere, the problem is that the same counties exist in different states. Therefore, all combinations are returned. Hence, I need to specify two arguments: the county’s name and state.\n\nelection_data16 |> \n  rename(county = name) |> \n  right_join(demographic_data, by = c(\"county\" = \"name\", \"state\"))\n\n# A tibble: 2,000 × 17\n   county   state votes…¹ votes…² total…³ per_d…⁴ per_g…⁵ diff_…⁶ winner party…⁷\n   <chr>    <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>  <chr>  \n 1 Adams C… IL       7633   22732   31770   0.240   0.716   15099 Trump  Republ…\n 2 Alexand… IL       1262    1496    2820   0.448   0.530     234 Trump  Republ…\n 3 Bond Co… IL       2066    4884    7462   0.277   0.655    2818 Trump  Republ…\n 4 Boone C… IL       8952   12261   22604   0.396   0.542    3309 Trump  Republ…\n 5 Brown C… IL        475    1776    2336   0.203   0.760    1301 Trump  Republ…\n 6 Bureau … IL       6010    9264   16303   0.369   0.568    3254 Trump  Republ…\n 7 Calhoun… IL        739    1719    2556   0.289   0.673     980 Trump  Republ…\n 8 Carroll… IL       2437    4428    7354   0.331   0.602    1991 Trump  Republ…\n 9 Cass Co… IL       1617    3216    5054   0.320   0.636    1599 Trump  Republ…\n10 Champai… IL      49694   33235   89196   0.557   0.373   16459 Clint… Democr…\n# … with 1,990 more rows, 7 more variables: pop <dbl>, female <dbl>,\n#   white <dbl>, black <dbl>, travel_time <dbl>, land_area <dbl>,\n#   hh_income <dbl>, and abbreviated variable names ¹​votes_dem_2016,\n#   ²​votes_gop_2016, ³​total_votes_2016, ⁴​per_dem_2016, ⁵​per_gop_2016,\n#   ⁶​diff_2016, ⁷​partywinner16\n\n\nLeft joins return all rows which are in x. If a column is in x but not in y, an NA will be included at this position. Right joins work vice versa.\n\n\n3.2.4 inner_join()\n\nelection_data16 |> \n  inner_join(demographic_data)\n\nJoining, by = c(\"name\", \"state\")\n\n\n# A tibble: 2,000 × 17\n   name     state votes…¹ votes…² total…³ per_d…⁴ per_g…⁵ diff_…⁶ winner party…⁷\n   <chr>    <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>  <chr>  \n 1 Adams C… IL       7633   22732   31770   0.240   0.716   15099 Trump  Republ…\n 2 Alexand… IL       1262    1496    2820   0.448   0.530     234 Trump  Republ…\n 3 Bond Co… IL       2066    4884    7462   0.277   0.655    2818 Trump  Republ…\n 4 Boone C… IL       8952   12261   22604   0.396   0.542    3309 Trump  Republ…\n 5 Brown C… IL        475    1776    2336   0.203   0.760    1301 Trump  Republ…\n 6 Bureau … IL       6010    9264   16303   0.369   0.568    3254 Trump  Republ…\n 7 Calhoun… IL        739    1719    2556   0.289   0.673     980 Trump  Republ…\n 8 Carroll… IL       2437    4428    7354   0.331   0.602    1991 Trump  Republ…\n 9 Cass Co… IL       1617    3216    5054   0.320   0.636    1599 Trump  Republ…\n10 Champai… IL      49694   33235   89196   0.557   0.373   16459 Clint… Democr…\n# … with 1,990 more rows, 7 more variables: pop <dbl>, female <dbl>,\n#   white <dbl>, black <dbl>, travel_time <dbl>, land_area <dbl>,\n#   hh_income <dbl>, and abbreviated variable names ¹​votes_dem_2016,\n#   ²​votes_gop_2016, ³​total_votes_2016, ⁴​per_dem_2016, ⁵​per_gop_2016,\n#   ⁶​diff_2016, ⁷​partywinner16\n\n\nAn inner_join() returns all rows which are in x and y.\n\n\n3.2.5 full_join()\n\nelection_data16 |> \n  full_join(demographic_data)\n\nJoining, by = c(\"name\", \"state\")\n\n\n# A tibble: 3,141 × 17\n   name     state votes…¹ votes…² total…³ per_d…⁴ per_g…⁵ diff_…⁶ winner party…⁷\n   <chr>    <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>  <chr>  \n 1 Adams C… IL       7633   22732   31770   0.240   0.716   15099 Trump  Republ…\n 2 Alexand… IL       1262    1496    2820   0.448   0.530     234 Trump  Republ…\n 3 Bond Co… IL       2066    4884    7462   0.277   0.655    2818 Trump  Republ…\n 4 Boone C… IL       8952   12261   22604   0.396   0.542    3309 Trump  Republ…\n 5 Brown C… IL        475    1776    2336   0.203   0.760    1301 Trump  Republ…\n 6 Bureau … IL       6010    9264   16303   0.369   0.568    3254 Trump  Republ…\n 7 Calhoun… IL        739    1719    2556   0.289   0.673     980 Trump  Republ…\n 8 Carroll… IL       2437    4428    7354   0.331   0.602    1991 Trump  Republ…\n 9 Cass Co… IL       1617    3216    5054   0.320   0.636    1599 Trump  Republ…\n10 Champai… IL      49694   33235   89196   0.557   0.373   16459 Clint… Democr…\n# … with 3,131 more rows, 7 more variables: pop <dbl>, female <dbl>,\n#   white <dbl>, black <dbl>, travel_time <dbl>, land_area <dbl>,\n#   hh_income <dbl>, and abbreviated variable names ¹​votes_dem_2016,\n#   ²​votes_gop_2016, ³​total_votes_2016, ⁴​per_dem_2016, ⁵​per_gop_2016,\n#   ⁶​diff_2016, ⁷​partywinner16\n\n\nA full_join() returns rows and columns from both x and y.\n\n\n3.2.6 semi_join()\nFiltering joins only keep the cases from x, no data set is added.\n\nelection_data16 |> \n  semi_join(demographic_data)\n\nJoining, by = c(\"name\", \"state\")\n\n\n# A tibble: 2,000 × 10\n   name     state votes…¹ votes…² total…³ per_d…⁴ per_g…⁵ diff_…⁶ winner party…⁷\n   <chr>    <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>  <chr>  \n 1 Adams C… IL       7633   22732   31770   0.240   0.716   15099 Trump  Republ…\n 2 Alexand… IL       1262    1496    2820   0.448   0.530     234 Trump  Republ…\n 3 Bond Co… IL       2066    4884    7462   0.277   0.655    2818 Trump  Republ…\n 4 Boone C… IL       8952   12261   22604   0.396   0.542    3309 Trump  Republ…\n 5 Brown C… IL        475    1776    2336   0.203   0.760    1301 Trump  Republ…\n 6 Bureau … IL       6010    9264   16303   0.369   0.568    3254 Trump  Republ…\n 7 Calhoun… IL        739    1719    2556   0.289   0.673     980 Trump  Republ…\n 8 Carroll… IL       2437    4428    7354   0.331   0.602    1991 Trump  Republ…\n 9 Cass Co… IL       1617    3216    5054   0.320   0.636    1599 Trump  Republ…\n10 Champai… IL      49694   33235   89196   0.557   0.373   16459 Clint… Democr…\n# … with 1,990 more rows, and abbreviated variable names ¹​votes_dem_2016,\n#   ²​votes_gop_2016, ³​total_votes_2016, ⁴​per_dem_2016, ⁵​per_gop_2016,\n#   ⁶​diff_2016, ⁷​partywinner16\n\n\nThe semi_join() returns all rows from x with matching values in y. You can compare it to a right_join() but without adding the columns of y.\n\n\n3.2.7 anti_join()\n\nelection_data16 |> \n  anti_join(demographic_data)\n\nJoining, by = c(\"name\", \"state\")\n\n\n# A tibble: 1,141 × 10\n   name     state votes…¹ votes…² total…³ per_d…⁴ per_g…⁵ diff_…⁶ winner party…⁷\n   <chr>    <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>  <chr>  \n 1 Onslow … NC      17156   36342   55364   0.310   0.656   19186 Trump  Republ…\n 2 Orange … NC      59105   18373   79830   0.740   0.230   40732 Clint… Democr…\n 3 Pamlico… NC       2427    4225    6772   0.358   0.624    1798 Trump  Republ…\n 4 Pasquot… NC       8455    8082   16964   0.498   0.476     373 Clint… Democr…\n 5 Pender … NC       9086   17317   27072   0.336   0.640    8231 Trump  Republ…\n 6 Perquim… NC       2291    4143    6595   0.347   0.628    1852 Trump  Republ…\n 7 Person … NC       7772   11116   19303   0.403   0.576    3344 Trump  Republ…\n 8 Pitt Co… NC      40967   35191   78264   0.523   0.450    5776 Clint… Democr…\n 9 Polk Co… NC       3715    6738   10723   0.346   0.628    3023 Trump  Republ…\n10 Randolp… NC      13074   49156   63615   0.206   0.773   36082 Trump  Republ…\n# … with 1,131 more rows, and abbreviated variable names ¹​votes_dem_2016,\n#   ²​votes_gop_2016, ³​total_votes_2016, ⁴​per_dem_2016, ⁵​per_gop_2016,\n#   ⁶​diff_2016, ⁷​partywinner16\n\n\nanti_join() returns all rows from x with no matching rows in y.\n\n\n3.2.8 bind_rows() and bind_cols()\nBinding tibbles together is made easy using the bind_*() functions. bind_rows() binds them together by rows, bind_cols() by columns. For the former, it is important that column names are matching. Otherwise, the non-matching ones will be added as separate columns and NAs introduced. IDs can be added by using the .id = argument, where the name of the id column can be specified.\n\nelection_data16 |> \n  semi_join(demographic_data) |> \n  bind_rows(election_data16 |>\n              anti_join(demographic_data),\n            .id = \"id\")\n\nJoining, by = c(\"name\", \"state\")\nJoining, by = c(\"name\", \"state\")\n\n\n# A tibble: 3,141 × 11\n   id    name       state votes…¹ votes…² total…³ per_d…⁴ per_g…⁵ diff_…⁶ winner\n   <chr> <chr>      <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr> \n 1 1     Adams Cou… IL       7633   22732   31770   0.240   0.716   15099 Trump \n 2 1     Alexander… IL       1262    1496    2820   0.448   0.530     234 Trump \n 3 1     Bond Coun… IL       2066    4884    7462   0.277   0.655    2818 Trump \n 4 1     Boone Cou… IL       8952   12261   22604   0.396   0.542    3309 Trump \n 5 1     Brown Cou… IL        475    1776    2336   0.203   0.760    1301 Trump \n 6 1     Bureau Co… IL       6010    9264   16303   0.369   0.568    3254 Trump \n 7 1     Calhoun C… IL        739    1719    2556   0.289   0.673     980 Trump \n 8 1     Carroll C… IL       2437    4428    7354   0.331   0.602    1991 Trump \n 9 1     Cass Coun… IL       1617    3216    5054   0.320   0.636    1599 Trump \n10 1     Champaign… IL      49694   33235   89196   0.557   0.373   16459 Clint…\n# … with 3,131 more rows, 1 more variable: partywinner16 <chr>, and abbreviated\n#   variable names ¹​votes_dem_2016, ²​votes_gop_2016, ³​total_votes_2016,\n#   ⁴​per_dem_2016, ⁵​per_gop_2016, ⁶​diff_2016\n\n\nFor bind_cols(), the length has to be the same. Duplicated column names will be changed.\n\nelection_data12 |> bind_cols(election_data16)\n\nNew names:\n• `name` -> `name...1`\n• `state` -> `state...2`\n• `winner` -> `winner...6`\n• `partywinner16` -> `partywinner16...7`\n• `name` -> `name...10`\n• `state` -> `state...11`\n• `winner` -> `winner...18`\n• `partywinner16` -> `partywinner16...19`\n\n\n# A tibble: 3,141 × 19\n   name...1      state…¹ per_d…² per_g…³ diff_…⁴ winne…⁵ party…⁶ winne…⁷ party…⁸\n   <chr>         <chr>     <dbl>   <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>  \n 1 Adams County  IL        0.315   0.667   10744 Trump   Republ… Romney  Republ…\n 2 Alexander Co… IL        0.561   0.425     476 Trump   Republ… Obama   Democr…\n 3 Bond County   IL        0.412   0.559    1075 Trump   Republ… Romney  Republ…\n 4 Boone County  IL        0.463   0.520    1216 Trump   Republ… Romney  Republ…\n 5 Brown County  IL        0.333   0.640     724 Trump   Republ… Romney  Republ…\n 6 Bureau County IL        0.489   0.491      33 Trump   Republ… Romney  Republ…\n 7 Calhoun Coun… IL        0.419   0.559     360 Trump   Republ… Romney  Republ…\n 8 Carroll Coun… IL        0.496   0.482     107 Trump   Republ… Obama   Democr…\n 9 Cass County   IL        0.422   0.557     657 Trump   Republ… Romney  Republ…\n10 Champaign Co… IL        0.520   0.452    5292 Clinton Democr… Obama   Democr…\n# … with 3,131 more rows, 10 more variables: name...10 <chr>, state...11 <chr>,\n#   votes_dem_2016 <dbl>, votes_gop_2016 <dbl>, total_votes_2016 <dbl>,\n#   per_dem_2016 <dbl>, per_gop_2016 <dbl>, diff_2016 <dbl>, winner...18 <chr>,\n#   partywinner16...19 <chr>, and abbreviated variable names ¹​state...2,\n#   ²​per_dem_2012, ³​per_gop_2012, ⁴​diff_2012, ⁵​winner...6, ⁶​partywinner16...7,\n#   ⁷​winner12, ⁸​partywinner12"
  },
  {
    "objectID": "dplyr.html#further-links",
    "href": "dplyr.html#further-links",
    "title": "3  Manipulation with dplyr",
    "section": "3.3 Further links",
    "text": "3.3 Further links\n\nChapter in R4DS\nMore on window functions in the vignette: vignette(\"window-functions\")\nAgain, the cheatsheet\nA tutorial on YouTube\nAnother introduction can be found here.\nThe chapter in R4DS has some nice diagrams.\nYou can also consult the introverse package if you need help with the packages covered here – introverse::show_topics(\"dplyr\") will give you an overview of dplyr’s functions, and get_help(\"name of function\") will help you with the respective function."
  },
  {
    "objectID": "forcats_lubridate.html",
    "href": "forcats_lubridate.html",
    "title": "4  Factors with forcats",
    "section": "",
    "text": "Factors are used in R to represent categorical data. In the following, I will briefly introduce you to the forcats package (nice anagram, Hadley!). Factors are augmented vectors which build upon integers. If you want to learn more about them, consider reading this paper."
  },
  {
    "objectID": "forcats_lubridate.html#creating-a-factor",
    "href": "forcats_lubridate.html#creating-a-factor",
    "title": "4  Factors with forcats",
    "section": "4.1 Creating a factor",
    "text": "4.1 Creating a factor\nYou can create a factor in two manners.\n\nTake a character vector and coerce it to a factor\n\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nparties <- c(\"AfD\", \"CDU\", \"CSU\", \"FDP\", \"Greens\", \"Leftists\", \"SPD\")\nparties_fct <- as_factor(parties)\n\ntypeof(parties_fct)\n\n[1] \"integer\"\n\n\n\nCreate it from scratch by providing levels and a vector respectively\n\n\nparty_sample <- c(\n  sample(parties, 49, replace = TRUE), \n  \"CUD\"\n  )\n\nfactor(party_sample, levels = parties)\n\n [1] Greens   AfD      Leftists CSU      SPD      SPD      CSU      FDP     \n [9] AfD      Leftists CDU      AfD      FDP      AfD      FDP      CSU     \n[17] AfD      SPD      SPD      FDP      FDP      CDU      FDP      AfD     \n[25] CSU      FDP      AfD      CSU      AfD      CSU      FDP      AfD     \n[33] AfD      AfD      AfD      AfD      CSU      CDU      Leftists CDU     \n[41] FDP      AfD      CSU      Leftists FDP      SPD      AfD      FDP     \n[49] FDP      <NA>    \nLevels: AfD CDU CSU FDP Greens Leftists SPD\n\n\nIf you want to access the levels, use levels()\n\nlevels(parties_fct)\n\n[1] \"AfD\"      \"CDU\"      \"CSU\"      \"FDP\"      \"Greens\"   \"Leftists\" \"SPD\""
  },
  {
    "objectID": "forcats_lubridate.html#some-basic-operations",
    "href": "forcats_lubridate.html#some-basic-operations",
    "title": "4  Factors with forcats",
    "section": "4.2 Some basic operations",
    "text": "4.2 Some basic operations\nI will have a further look into factors using data on the presidential elections in the U.S.\n\nelection_data <- read_csv(\"https://www.dropbox.com/s/82xuhcwhv7wh314/pres16results.csv?dl=1\") |> \n  drop_na() |> \n  glimpse()\n\nRows: 18475 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): county, fips, cand, st, lead\ndbl (4): pct_report, votes, total_votes, pct\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nRows: 18,007\nColumns: 9\n$ county      <chr> \"Los Angeles County\", \"Los Angeles County\", \"Los Angeles C…\n$ fips        <chr> \"6037\", \"6037\", \"6037\", \"6037\", \"6037\", \"17031\", \"17031\", …\n$ cand        <chr> \"Hillary Clinton\", \"Donald Trump\", \"Gary Johnson\", \"Jill S…\n$ st          <chr> \"CA\", \"CA\", \"CA\", \"CA\", \"CA\", \"IL\", \"IL\", \"IL\", \"IL\", \"TX\"…\n$ pct_report  <dbl> 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9746, 0.9746, 0.…\n$ votes       <dbl> 1654626, 542591, 56905, 46682, 13471, 1528582, 440213, 559…\n$ total_votes <dbl> 2314275, 2314275, 2314275, 2314275, 2314275, 2055215, 2055…\n$ pct         <dbl> 0.714965162, 0.234453987, 0.024588694, 0.020171328, 0.0058…\n$ lead        <chr> \"Hillary Clinton\", \"Hillary Clinton\", \"Hillary Clinton\", \"…\n\n\nWhich variables should be converted to factors? – county, cand, st, lead.\n\nelection_data_w_fct <- election_data |> \n  mutate(county = as_factor(county),\n         candidate = as_factor(cand),\n         state = as_factor(st),\n         lead = as_factor(lead)) |> \n  select(county, candidate, state, pct_report:pct, lead)\n\n\n4.2.1 Reordering factors\nSometimes you want to reorder factors – for instance, when you want to create plots. (Note: you will learn more on plots in the next session on data visualization)\n\nelection_data_w_fct |> \n  group_by(state) |> \n  summarize(sum_votes = sum(votes)) |> \nggplot(aes(x = sum_votes, y = state)) +\n  geom_point()\n\n\n\n\nTwo orders would make sense: alphabetical and according to their number of votes. fct_reorder() takes another variable and orders the factor according to it.\n\nelection_data_w_fct |>\n  group_by(state) |> \n  summarize(sum_votes = sum(votes)) |> \n  mutate(state = fct_reorder(state, sum_votes)) |> \n  ggplot(aes(x = sum_votes, y = state)) +\n    geom_point()\n\n\n\n\nIf you want to have it ordered the other way round, multiply the ordering variable with -1:\n\nelection_data_w_fct |> \n  group_by(state) |> \n  summarize(sum_votes = sum(votes)) |> \n  mutate(state = fct_reorder(state, sum_votes*(-1))) |> \n  ggplot(aes(x = sum_votes, y = state)) +\n    geom_point()\n\n\n\n\nYou could also achieve this by calling fct_rev() afterwards: it reverses the order of the factor.\n\nelection_data_w_fct |> \n  group_by(state) |> \n  summarize(sum_votes = sum(votes)) |> \n  mutate(state = fct_reorder(state, sum_votes),\n         state = fct_rev(state)) |> \nggplot(aes(x = sum_votes, y = state)) +\n  geom_point()\n\n\n\n\nIf you want to do bar plots, which you can use to depict the frequency of a value, you can order them according to the frequency they appear in using fct_infreq():\n\nelection_data_w_fct |> \n  mutate(lead = lead |> fct_infreq() |> fct_rev()) |> \n  ggplot(aes(x = lead)) +\n    geom_bar()\n\n\n\n\n\n\n4.2.2 Modifying levels\nRemember the first factor? You need to put some graphs together and decide that you would rather like to use the original German names for the parties. Go for fct_recode().\n\nparties_fct_ger <- fct_recode(parties_fct,\n  \"Buendnis90/Die Gruenen\" = \"Greens\", \n  \"Die Linke\" = \"Leftists\"\n)\n\nDamn, now the levels are not in alphabetical order anymore.\n\nlevels(parties_fct_ger)\n\n[1] \"AfD\"                    \"CDU\"                    \"CSU\"                   \n[4] \"FDP\"                    \"Buendnis90/Die Gruenen\" \"Die Linke\"             \n[7] \"SPD\"                   \n\n\nIn this case, this can be done pretty quickly. Just copy the levels and manipulate the order:\n\nparties_fct_ger_alphabetical <- fct_relevel(parties_fct_ger, \n                                            c(\"AfD\", \n                                              \"Buendnis90/Die Gruenen\", \n                                              \"CDU\", \n                                              \"CSU\",\n                                              \"Die Linke\",\n                                              \"FDP\",\n                                              \"SPD\"))\nlevels(parties_fct_ger_alphabetical)\n\n[1] \"AfD\"                    \"Buendnis90/Die Gruenen\" \"CDU\"                   \n[4] \"CSU\"                    \"Die Linke\"              \"FDP\"                   \n[7] \"SPD\"                   \n\n\nNow you need to write something for someone who is not particular familiar with the political landscape in Germany and rather wants “left,” “center,” and “right” instead of the party’s names. Give fct_collapse() a shot – and feel free to change it if you disagree with my classification.\n\nlcr_ger <- fct_collapse(parties_fct,\n                        left = c(\"Leftists\", \"Greens\", \"SPD\"),\n                        centre = c(\"CDU\", \"CSU\", \"FDP\"),\n                        right = c(\"AfD\")\n                        )\n\nAnother thing you could do – and this is handy for the election data set – is collapsing things together according to their frequency of appearance. In the case of the election data set, this might be handy to lump together the candidates into three groups: Donald Trump, Hillary Clinton, and other.\n\nelection_data_w_fct |> \n  mutate(candidate = fct_lump(candidate, n = 2))\n\n# A tibble: 18,007 × 8\n   county             candidate       state pct_r…¹  votes total…²     pct lead \n   <fct>              <fct>           <fct>   <dbl>  <dbl>   <dbl>   <dbl> <fct>\n 1 Los Angeles County Hillary Clinton CA      1     1.65e6 2314275 0.715   Hill…\n 2 Los Angeles County Donald Trump    CA      1     5.43e5 2314275 0.234   Hill…\n 3 Los Angeles County Gary Johnson    CA      1     5.69e4 2314275 0.0246  Hill…\n 4 Los Angeles County Other           CA      1     4.67e4 2314275 0.0202  Hill…\n 5 Los Angeles County Other           CA      1     1.35e4 2314275 0.00582 Hill…\n 6 Cook County        Hillary Clinton IL      0.975 1.53e6 2055215 0.744   Hill…\n 7 Cook County        Donald Trump    IL      0.975 4.40e5 2055215 0.214   Hill…\n 8 Cook County        Gary Johnson    IL      0.975 5.59e4 2055215 0.0272  Hill…\n 9 Cook County        Other           IL      0.975 3.05e4 2055215 0.0149  Hill…\n10 Harris County      Hillary Clinton TX      1     7.06e5 1302887 0.542   Hill…\n# … with 17,997 more rows, and abbreviated variable names ¹​pct_report,\n#   ²​total_votes\n\n\nThe problem here is that Gary Johnson appears as often as the two other candidates (have you ever heard of him?). Hence, fct_lump() cannot decide which levels to lump together. However, it has saved me a couple lines of code:\n\nelection_data_w_fct |> \n  mutate(candidate = fct_lump(candidate, n = 2) |> \n           fct_recode(\"Other\" = \"Gary Johnson\"))\n\n# A tibble: 18,007 × 8\n   county             candidate       state pct_r…¹  votes total…²     pct lead \n   <fct>              <fct>           <fct>   <dbl>  <dbl>   <dbl>   <dbl> <fct>\n 1 Los Angeles County Hillary Clinton CA      1     1.65e6 2314275 0.715   Hill…\n 2 Los Angeles County Donald Trump    CA      1     5.43e5 2314275 0.234   Hill…\n 3 Los Angeles County Other           CA      1     5.69e4 2314275 0.0246  Hill…\n 4 Los Angeles County Other           CA      1     4.67e4 2314275 0.0202  Hill…\n 5 Los Angeles County Other           CA      1     1.35e4 2314275 0.00582 Hill…\n 6 Cook County        Hillary Clinton IL      0.975 1.53e6 2055215 0.744   Hill…\n 7 Cook County        Donald Trump    IL      0.975 4.40e5 2055215 0.214   Hill…\n 8 Cook County        Other           IL      0.975 5.59e4 2055215 0.0272  Hill…\n 9 Cook County        Other           IL      0.975 3.05e4 2055215 0.0149  Hill…\n10 Harris County      Hillary Clinton TX      1     7.06e5 1302887 0.542   Hill…\n# … with 17,997 more rows, and abbreviated variable names ¹​pct_report,\n#   ²​total_votes"
  },
  {
    "objectID": "forcats_lubridate.html#further-links",
    "href": "forcats_lubridate.html#further-links",
    "title": "4  Factors with forcats",
    "section": "4.3 Further links",
    "text": "4.3 Further links\n\nThe chapter in R4DS\nIf you want to learn more about factors, consider reading this paper\nAnother tutorial"
  },
  {
    "objectID": "forcats_lubridate.html#dates",
    "href": "forcats_lubridate.html#dates",
    "title": "4  Factors with forcats",
    "section": "4.4 Dates",
    "text": "4.4 Dates\nIn the script about data import you have learned about how to parse dates: for parse_date(), dates have to be formatted in a certain standard or you need to provide it with one. This is often tedious. That’s where the lubridate package jumps in: it provides you with parsing functions that are more handy. They all take a character vector and the function’s name is related to the order of the date’s components. The functions recognize non-digit separators and are, therefore, most of the time a hassle-free way to parse dates.\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nymd(\"2000-02-29\")\n\n[1] \"2000-02-29\"\n\nymd(\"2000 02 29\")\n\n[1] \"2000-02-29\"\n\ndmy(\"29.02.2000\")\n\n[1] \"2000-02-29\"\n\n\nThere is also a function for quarters:\n\nyq(\"2000: Q3\")\n\n[1] \"2000-07-01\""
  },
  {
    "objectID": "forcats_lubridate.html#date-times",
    "href": "forcats_lubridate.html#date-times",
    "title": "4  Factors with forcats",
    "section": "4.5 Date-times",
    "text": "4.5 Date-times\nThey also have date-time equivalents:\n\nymd_hms(\"2000-02-29 14:00:00\")\n\n[1] \"2000-02-29 14:00:00 UTC\"\n\nmdy_hm(\"02-29-2000 10.04\")\n\n[1] \"2000-02-29 10:04:00 UTC\"\n\ndmy_h(\"29.02.2000 10\")\n\n[1] \"2000-02-29 10:00:00 UTC\""
  },
  {
    "objectID": "forcats_lubridate.html#further-handy-things",
    "href": "forcats_lubridate.html#further-handy-things",
    "title": "4  Factors with forcats",
    "section": "4.6 Further handy things",
    "text": "4.6 Further handy things\n\ntoday()\n\n[1] \"2022-11-21\"\n\nnow()\n\n[1] \"2022-11-21 16:09:41 CET\""
  },
  {
    "objectID": "forcats_lubridate.html#manipulating-dates",
    "href": "forcats_lubridate.html#manipulating-dates",
    "title": "4  Factors with forcats",
    "section": "4.7 Manipulating dates",
    "text": "4.7 Manipulating dates\n\n4.7.1 Components\nYou can also extract singular components from dates using the following functions:\n\nexample_datetime <- ymd_hms(\"2000-02-29 14:00:00\")\n\ndate(example_datetime)\n\n[1] \"2000-02-29\"\n\nyear(example_datetime)\n\n[1] 2000\n\nmonth(example_datetime)\n\n[1] 2\n\nday(example_datetime)\n\n[1] 29\n\nhour(example_datetime)\n\n[1] 14\n\nminute(example_datetime)\n\n[1] 0\n\nsecond(example_datetime)\n\n[1] 0\n\nweek(example_datetime)\n\n[1] 9\n\nquarter(example_datetime)\n\n[1] 1\n\nsemester(example_datetime)\n\n[1] 1\n\nam(example_datetime)\n\n[1] FALSE\n\npm(example_datetime)\n\n[1] TRUE\n\nleap_year(example_datetime)\n\n[1] TRUE\n\n\n\n\n4.7.2 Rounding\nSometimes you will also want to round dates – e.g., if you count observations per month or something similar.\n\nfloor_date(example_datetime, unit = \"month\")\n\n[1] \"2000-02-01 UTC\"\n\nfloor_date(example_datetime, unit = \"3 months\")\n\n[1] \"2000-01-01 UTC\"\n\nround_date(example_datetime, unit = \"year\")\n\n[1] \"2000-01-01 UTC\"\n\nceiling_date(example_datetime, unit = \"day\")\n\n[1] \"2000-03-01 UTC\"\n\nrollback(example_datetime, roll_to_first = FALSE, preserve_hms = TRUE)\n\n[1] \"2000-01-31 14:00:00 UTC\"\n\nrollback(example_datetime, roll_to_first = TRUE, preserve_hms = FALSE)\n\n[1] \"2000-02-01 UTC\""
  },
  {
    "objectID": "forcats_lubridate.html#time-zones",
    "href": "forcats_lubridate.html#time-zones",
    "title": "4  Factors with forcats",
    "section": "4.8 Time zones",
    "text": "4.8 Time zones\nDealing with time zones is tedious. By default, R sets the time zone of every date you provide it with to UTC (Coordinated Universal Time). However, sometimes you need to change it – e.g., when you deal with flight data. lubridate provides you with some handy functions for doing so. Generally speaking, you will not often work with them.\nFirst, you need to know which arguments you can provide the functions with – or, put differently, the names of the time zones.\n\nhead(OlsonNames()) # wrapped it with head() because it's 593 in total\n\n[1] \"Africa/Abidjan\"     \"Africa/Accra\"       \"Africa/Addis_Ababa\"\n[4] \"Africa/Algiers\"     \"Africa/Asmara\"      \"Africa/Asmera\"     \n\n\nIf you want to set a new time zone to a date-object – hence, 2 o’clock UTC becomes 2 o’clock CET – use force_tz():\n\nforce_tz(example_datetime, tzone = \"CET\")\n\n[1] \"2000-02-29 14:00:00 CET\"\n\n\nIf you want to transform your date-time object to a new time zone, preserving its time – for example, for appointments all around the world – use with_tz(). If you use the aforementioned now() function, lubridate will use your computer’s time zone:\n\nwith_tz(now(), tzone = \"US/Eastern\")\n\n[1] \"2022-11-21 10:09:41 EST\""
  },
  {
    "objectID": "forcats_lubridate.html#periods-durations-intervals",
    "href": "forcats_lubridate.html#periods-durations-intervals",
    "title": "4  Factors with forcats",
    "section": "4.9 Periods, durations, intervals",
    "text": "4.9 Periods, durations, intervals\nYou will also want to do some calculations based on the dates and times you have parsed.\n\n4.9.1 Periods\nA period can be created using a pluralized name of a time unit.\n\nmonths(3) + days(5)\n\n[1] \"3m 5d 0H 0M 0S\"\n\n\nAnother way of doing so – which is suited for automation – is period():\n\nperiod(num = 5, unit = \"years\")\n\n[1] \"5y 0m 0d 0H 0M 0S\"\n\n\nYou can also set multiple arguments:\n\nperiod(num = 1:5, units = c(\"years\", \"months\", \"days\", \"hours\", \"minutes\"))\n\n[1] \"1y 2m 3d 4H 5M 0S\"\n\n\n\n\n4.9.2 Durations\nDurations can be used to model physical processes. They are stored in seconds and can be created by prefixing the name of a period:\n\ndweeks(x = 1)\n\n[1] \"604800s (~1 weeks)\"\n\n\nAgain, there’s a constructor function:\n\nduration(num = 1:5, units = c(\"years\", \"months\", \"days\", \"hours\", \"minutes\"))\n\n[1] \"31557600s (~1 years)\"  \"5259600s (~8.7 weeks)\" \"259200s (~3 days)\"    \n[4] \"14400s (~4 hours)\"     \"300s (~5 minutes)\"    \n\n\nHow long do I have to wait until Christmas?\n\nymd(\"2022-12-24\")-today()\n\nTime difference of 33 days\n\n\n\n\n4.9.3 Intervals\nIntervals can be created by using the interval() function or by using the %--% operator.\n\ninterval(today(), ymd(\"2020-12-24\"))\n\n[1] 2022-11-21 UTC--2020-12-24 UTC\n\ntoday() %--% ymd(\"2020-12-24\")\n\n[1] 2022-11-21 UTC--2020-12-24 UTC\n\n\nYou can divide an interval by a duration to determine its physical length:\n\nchristmas <- today() %--% ymd(\"2020-12-24\")\nchristmas/ddays(x = 1)\n\n[1] -697\n\n\nYou can divide an interval by a period to determine its implied length in clock time:\n\nchristmas/days(x = 1)\n\n[1] -697\n\n\nIf you want to know its length in seconds, you can also do int_length():\n\nint_length(christmas)\n\n[1] -60220800\n\n\nThere are also some other things you can do with intervals:\nDoes the start of the winter semester fall within the period between now and Christmas?\n\nymd(\"2020-11-04\") %within% interval(today(), ymd(\"2020-12-24\"))\n\n[1] FALSE\n\n\nReverse the direction of the interval:\n\nint_flip(interval(today(), ymd(\"2020-12-24\")))\n\n[1] 2020-12-24 UTC--2022-11-21 UTC\n\n\nYou can also shift an interval:\ntoday until Christmas –> tomorrow until December 25:\n\nint_shift(christmas, by = days(1))\n\n[1] 2022-11-22 UTC--2020-12-25 UTC"
  },
  {
    "objectID": "forcats_lubridate.html#further-links-1",
    "href": "forcats_lubridate.html#further-links-1",
    "title": "4  Factors with forcats",
    "section": "4.10 Further links",
    "text": "4.10 Further links\n\nThe lubridate page which also contains a cheatsheet\nThe R4DS chapter"
  },
  {
    "objectID": "ggplot2.html",
    "href": "ggplot2.html",
    "title": "5  Visualizations with ggplot2",
    "section": "",
    "text": "“The purpose of visualization is insight, not pictures.” – Ben A. Shneiderman\nIn R, the dominant package for visualizing data is ggplot2 which belongs to the tidyverse."
  },
  {
    "objectID": "ggplot2.html#the-layered-grammar-of-graphics",
    "href": "ggplot2.html#the-layered-grammar-of-graphics",
    "title": "5  Visualizations with ggplot2",
    "section": "5.1 The “layered grammar of graphics”",
    "text": "5.1 The “layered grammar of graphics”\nggplot2 works with tibbles and the data needs to be in a tidy format. It builds graphics using “the layered grammar of graphics.” (wickham2010?)\n\nlibrary(tidyverse)\n\npublishers <- read_csv(\"https://www.dropbox.com/s/e1r06gbvxobrsfm/publishers_places.csv?dl=1\")\n  \npublishers_filtered <- publishers |> \n  group_by(city) |> \n  filter(n() > 5) |> \n  drop_na()\n\nThis implies that you start with a base layer – the initial ggplot2 call.\n\nggplot(data = publishers_filtered)\n\n\n\n\nThe initial call produces an empty coordinate system. It can be filled with additional layers.\n\nggplot(data = publishers_filtered) +\n  geom_bar(aes(x = city)) \n\n\n\n\nUnlike the remainder of the tidyverse, ggplot2 uses a + instead of the pipe |>. If you use the pipe by accident, it will not work and an (informative) error message will appear.\n\n# ggplot(data = publishers_filtered) |> \n#   geom_bar(aes(x = city)) \n\n\n5.1.1 The layers\nIn general, a call looks like this:\n\nggplot(data = <DATA>) + \n  <GEOM_FUNCTION>(mapping = aes(<MAPPINGS>))\n\nAs you might have seen above, I provided the data in the initial ggplot call. Then, when I added the layer – the geom_bar() for a bar plot – I had to provide the mapping – which variables I wanted to plot – using aes(). This is referred to as the aesthetics. In my case, I wanted the cities to be projected to the x-axis. Since I was using geom_bar to create a bar plot, the number of occurrences of the respective cities were automatically counted and depicted on the y-axis. There are more geom_* functions and they all create different plots. Whether you can use them or not depends on the data you have at hand and/or the number of variables you want to plot. In the following, I will give you a brief overview of the most important geoms.\n\n5.1.1.1 One variable\nIf you only want to display one variable, the x- or y-axis, as you choose, will depict the variable’s value. The counterpart will display the frequency or density of those values.\n\n5.1.1.1.1 One variable – discrete\nHere, the only possible kind of visualization is a bar plot as shown above. If the visualization should look more fancy, e.g., with colored bars, you have several arguments at hand. If they should not be different for different kinds of data, they need to be specified outside the aes(). There are always different arguments and you can look them up using ?<GEOM_FUNCTION> and then looking at the Aesthetics section. Apart from that, you can also look at the ggplot2 cheatsheet.\n\nggplot(data = publishers_filtered) +\n  geom_bar(aes(x = city), fill = \"blue\") \n\n\n\n\n\n\n5.1.1.1.2 One variable – continuous\nIf you want to display a continuous variable’s distribution of values, you can use a histogram. Its geom_* function is geom_histogram():\n\nbillboard <- read_csv(\"https://www.dropbox.com/s/e5gbrpa1fsrtvj5/billboard.csv?dl=1\")\n\nRows: 317 Columns: 79\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (2): artist, track\ndbl  (65): wk1, wk2, wk3, wk4, wk5, wk6, wk7, wk8, wk9, wk10, wk11, wk12, wk...\nlgl  (11): wk66, wk67, wk68, wk69, wk70, wk71, wk72, wk73, wk74, wk75, wk76\ndate  (1): date.entered\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsong_tbl <- billboard |> \n  distinct(artist, track) |> \n  mutate(song_id = row_number())\n\nrank_tbl <- billboard |> \n  pivot_longer(cols = starts_with(\"wk\"), \n               names_to = \"week\", \n               names_prefix = \"wk\", \n               values_to = \"rank\") |> \n  mutate(week = as.numeric(week),\n         date = date.entered + (week-1) * 7) |> \n  drop_na() |> \n  left_join(song_tbl, by = c(\"artist\", \"track\")) |> \n  select(song_id, date, week, rank)\n\nHow does the distribution of songs over the weeks look like?\n\nggplot(data = rank_tbl) +\n  geom_histogram(aes(x = week))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nA smoothed histogram is geom_density():\n\nggplot(data = rank_tbl) +\n  geom_density(aes(x = week))\n\n\n\n\n\n\n\n5.1.1.2 Two variables\nIn the majority of cases, you will want to display the relationship between two variables, one on the x- and the other one on the y-axis.\n\n5.1.1.2.1 Both continuous\n\ncounty_data_midwest <- socviz::county_data |> \n  filter(census_region == \"Midwest\") |> \n  drop_na()\n\nIf both variables are continuous, the easiest option is to use a scatter plot.\n\nggplot(data = county_data_midwest) +\n  geom_point(aes(x = per_dem_2016, y = per_gop_2016))\n\n\n\n\nIf you don’t like dots, the shape = argument allows you to change the shape of the data points. There are also other arguments to change, for instance, transparency (alpha =) or size (size =). Find an overview of the allowed aesthetic specifications here.\n\nggplot(data = county_data_midwest) +\n  geom_point(aes(x = per_dem_2016, y = per_gop_2016), shape = \"cross\", size = 2)\n\n\n\n\nHere, it might make sense to color the points according to a categorical variable (state, in this case). If so, a legend is added which maps the colors to their respective values.\n\nggplot(data = county_data_midwest) +\n  geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = state))\n\n\n\n\nSince I look at the relationship between votes for the Republicans and the Democrats, and the U.S. is a two-party system, there is a fairly clear relationship between them both. This can also be depicted using geom_smooth():\n\nggplot(data = county_data_midwest) +\n  geom_smooth(aes(x = per_dem_2016, y = per_gop_2016, color = state))\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n\n\n\n\nHere, color = state has a different effect: each dimension of the categorical variable gets its own line.\nIf you do not want it to be smoothed, just use geom_line().\n\nggplot(data = county_data_midwest) +\n  geom_line(aes(x = per_dem_2016, y = per_gop_2016), color = \"grey\")\n\n\n\n\n\n\n5.1.1.2.2 Discrete X, continuous Y\nIn this case, different categories of data will be put on the x-axis and some of their properties will be displayed on the y-axis. The probably most prominent example for this type of plot is a box plot:\n\nggplot(data = county_data_midwest) +\n  geom_boxplot(aes(x = state, y = per_gop_2016))\n\n\n\n\n\n\n5.1.1.2.3 Both discrete\nIt is rarely the case that you want to depict two categorical variables in one plot. If so, you can use geom_jitter(). It is related to geom_point(). The difference is that with geom_jitter(), a little bit of noise is added to the dots, making them appear distinct.\n\nggplot(data = county_data_midwest) +\n  geom_jitter(aes(x = state, y = winner))\n\n\n\n\nAs opposed to:\n\nggplot(data = county_data_midwest) +\n  geom_point(aes(x = state, y = winner))\n\n\n\n\n\n\n\n\n5.1.2 Making them “publishable”\nSo far, I have only added one layer to the plot. This suffices for the most basic visualizations. The good thing about R and RMarkdown is, however, that you can write entire publications only using their means. Hence, the plots need to look awesome. This section is dedicated to how you can achieve this. First, I will touch upon how you can make them look good using scales. labs() allow you to add titles, captions, and axis labels. Finally, facet_* allows you to plot multiple plots into one.\n\n5.1.2.1 Scales\nScales can be used to take control of how the data’s values are mapped to the aesthetic’s visual values. You can find a more exhaustive tutorial on them here.\n\nscale_*_continuous – for dealing with continuous values. (you can find an exhaustive list of colors in R here)\n\n\nggplot(data = county_data_midwest) +\n  geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = white)) +\n  scale_x_continuous(limits = c(0, 1)) +\n  scale_y_continuous(limits = c(0, 1)) +\n  scale_color_gradient(low = \"green\",\n                       high = \"red\")\n\n\n\n\n\nscale_*_discrete – for dealing with discrete values\nscale_*_manual – manually mapping discrete values to visual values\n\n\nsocviz::county_data |> \n  filter(state %in% c(\"IA\", \"IL\", \"IN\", \"KS\")) |> \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = state)) +\n    scale_color_manual(values = c(\"IA\" = \"blue\", \"IL\" = \"green\", \"IN\" = \"red\", \"KS\" = \"purple\"),\n                       name = \"State\",\n                       breaks = waiver(),\n                       labels = c(\"Iowa\", \"Illinois\", \"Indiana\", \"Kansas\")) \n\nWarning: Removed 4 rows containing missing values (geom_point).\n\n\n\n\n\n\n\n5.1.2.2 Adding titles, captions, etc.\nNow you have modified the scales and colors – there is a lot more to be modified if you want to – but you have not added a meaningful title, a nice caption (where were the data obtained?), and the axes do not have proper names, too. This can be achieved using labs() (which is the abbreviation for labels).\n\nsocviz::county_data |> \n  filter(state %in% c(\"IA\", \"IL\", \"IN\", \"KS\")) |> \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = state)) +\n    scale_color_manual(values = c(\"IA\" = \"blue\", \"IL\" = \"green\", \"IN\" = \"red\", \"KS\" = \"purple\"),\n                       name = \"State\",\n                       breaks = waiver(),\n                       labels = c(\"Iowa\", \"Illinois\", \"Indiana\", \"Kansas\")) +\n    scale_x_continuous(limits = c(0, 1)) +\n    scale_y_continuous(limits = c(0, 1)) +\n    ggtitle(\"Relationship between percentages of votes for Democrats and Republicans in selected states in the Midwest\") +\n    xlab(\"Percentage of votes for the Democrats in 2016\") +\n    ylab(\"Percentage of votes for the Republicans in 2016\") \n\nWarning: Removed 4 rows containing missing values (geom_point).\n\n\n\n\n\nWell, that doesn’t look good, the title is too long. Inserting \\n – for new line – will do the trick.\n\nsocviz::county_data |> \n  filter(state %in% c(\"IA\", \"IL\", \"IN\", \"KS\")) |> \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = state)) +\n    scale_color_manual(values = c(\"IA\" = \"blue\", \"IL\" = \"green\", \"IN\" = \"red\", \"KS\" = \"purple\"),\n                      name = \"State\",\n                      breaks = waiver(),\n                      labels = c(\"Iowa\", \"Illinois\", \"Indiana\", \"Kansas\")) +\n    scale_x_continuous(limits = c(0, 1)) +\n    scale_y_continuous(limits = c(0, 1)) +\n    ggtitle(\"Relationship between percentages of votes for Democrats \\nand Republicans in selected states in the Midwest\") +\n    xlab(\"Percentage of votes for the Democrats in 2016\") +\n    ylab(\"Percentage of votes for the Republicans in 2016\") \n\nWarning: Removed 4 rows containing missing values (geom_point).\n\n\n\n\n\nHowever, providing it with three different layers just for labeling is pretty tedious. This is where labs() comes in handy.\n\nsocviz::county_data |> \n  filter(state %in% c(\"IA\", \"IL\", \"IN\", \"KS\")) |> \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = state)) +\n    scale_color_manual(values = c(\"IA\" = \"blue\", \"IL\" = \"green\", \"IN\" = \"red\", \"KS\" = \"purple\"),\n                      name = \"State\",\n                      breaks = waiver(),\n                      labels = c(\"Iowa\", \"Illinois\", \"Indiana\", \"Kansas\")) +\n    scale_x_continuous(limits = c(0, 1)) +\n    scale_y_continuous(limits = c(0, 1)) +\n    labs(title = \"Relationship between percentages of votes for Democrats \\nand Republicans in selected states in the Midwest\",\n         caption = \"Data obtained from the socviz R package\",\n         x = \"Percentage of votes for the Democrats in 2016\",\n         y = \"Percentage of votes for the Republicans in 2016\") \n\nWarning: Removed 4 rows containing missing values (geom_point).\n\n\n\n\n\n\n\n5.1.2.3 Facets\nThe original data set consists of four different census regions. If I were to compare them, I could color them accordingly.\n\nsocviz::county_data |> \n  drop_na() |> \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = census_region)) +\n    scale_x_continuous(limits = c(0, 1)) +\n    scale_y_continuous(limits = c(0, 1)) +\n    scale_color_discrete()\n\n\n\n\nDespite the coloring according to the different states, it is still hard to assess whether there really are differences. Apart from that, I would like to assess the impact the percentage of white people in the population has. This would be easier if I put them into individual graphs. I can achieve this using so-called facets. Facets enable me to divide the plot into subplots based on categorical variables. facet_wrap() puts them into a rectangular layout. The categorical variable needs to be provided prefixed with a tilde ~, nrow determines the number of rows.\n\nsocviz::county_data |> \n  drop_na() |> \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = white)) +\n    scale_x_continuous(limits = c(0, 1)) +\n    scale_y_continuous(limits = c(0, 1)) +\n    scale_color_gradient(low = \"green\",\n                         high = \"red\") +\n    facet_wrap(~census_region,\n               nrow = 2)\n\n\n\n\nApart from that, I can also spread it out using two different variables. Here, I will look at differences in the distribution of males and females in the counties split up by who won in 2016 and 2012. This can be achieved using facet_grid(categorical_variable_1~categorical_variable_2). The former one will be put into rows, the latter into columns.\n\nsocviz::county_data |> \n  drop_na() |> \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = white)) +\n    scale_x_continuous(limits = c(0, 1)) +\n    scale_y_continuous(limits = c(0, 1)) +\n    scale_color_gradient(low = \"green\",\n                         high = \"red\") +\n    facet_grid(winner~winner12)\n\n\n\n\nIf you want to facet using only one variable, put a dot at where the other variable would stand otherwise…\n\nsocviz::county_data |> \n  drop_na() |> \n  ggplot() +\n    geom_point(aes(x = per_dem_2016, y = per_gop_2016, color = white)) +\n    scale_x_continuous(limits = c(0, 1)) +\n    scale_y_continuous(limits = c(0, 1)) +\n    scale_color_gradient(low = \"green\",\n                         high = \"red\") +\n    facet_grid(.~winner)\n\n\n\n\n… or just use facet_wrap()."
  },
  {
    "objectID": "ggplot2.html#exporting-graphics",
    "href": "ggplot2.html#exporting-graphics",
    "title": "5  Visualizations with ggplot2",
    "section": "5.2 Exporting graphics",
    "text": "5.2 Exporting graphics\nIf you include the graphics in an RMarkdown document, make sure you use the proper chunk options (i.e., {r echo=FALSE, message=FALSE, warning=FALSE}).\nIf you, however, want to export it and put it into an MS Word document or so, you can just use the ggsave() function. By default, it just takes the last plot that has been created and saves it to a path that needs to be specified. If it contains a file extension, ggsave() just uses this one.\n\nggplot(mtcars, aes(mpg, wt)) +\n  geom_point()\n\nggsave(\"mtcars.pdf\", device = \"pdf\") #save it to pdf\nggsave(\"mtcars.png\") #save it to png\n\nggsave(\"mtcars.pdf\", width = 4, height = 4) #specify width and height -- in inches by default\nggsave(\"mtcars.pdf\", width = 20, height = 20, units = \"cm\") #change unit using the units argument"
  },
  {
    "objectID": "ggplot2.html#further-readings",
    "href": "ggplot2.html#further-readings",
    "title": "5  Visualizations with ggplot2",
    "section": "5.3 Further readings",
    "text": "5.3 Further readings\n\nggplot2 – the book.\nThe graphic cookbook for R.\nAnother tutorial.\nThe ggsave() function in further detail.\nYou can also consult the introverse package. introverse::show_topics(\"ggplot2\") will give you overviews of the respective package’s functions, and get_help(\"name of function\") will help you with the respective function."
  }
]