# Introduction to RStudio Projects and `readr`

As some of you are beginners, it might be hard for you to see the point in setting up Projects and a GitHub account already. The intermediate and advanced users among you, who are not familiar with projects and GitHub yet though, might also wonder what they would need it for: working with R has gone pretty well in the past, so why should you change this running system?  

I start out making points on why using Projects is useful. Then, I will provide step-by-step guidance on how to set them up. Since using GitHub is not that straight-forward, I will motivate why to use it and then link to a bigger tutorial covering the setup process (again by Jennifer Bryan, a statistic professor who also works at RStudio).

## RStudio Projects

### Motivation

Disclaimer: those things might not be entirely clear right away. However, I am deeply convinced that it is important that you use R and RStudio properly from the start. Otherwise it won't be as easy to re-build the right habits.

If you analyze data with R, one of the first things you do is to load in the data that you want to perform your analyses on. Then, you perform your analyses on them, and save the results in the (probably) same directory.  
When you load a data set into R, you might use the `readr` package and do `read_csv(absolute_file_path.csv)`. This becomes fairly painful if you need to read in more than one data set. Then, relative paths (i.e., where you start from a certain point in your file structure, e.g., your file folder) become more useful. 
How you CAN go across this is to use the `setwd(absolute_file_path_to_your_directory)` function. Here, `set` stands for set and `wd` stands for working directory. If you are not sure about what the current working directory actually is, you can use `getwd()` which is the equivalent to `setwd(file_path)`. This enables you to read in a data set -- if the file is in the working directory -- by only using `read_csv(file_name.csv)`.  
However, if you have ever worked on an R project with other people in a group and exchanged scripts regularly, you may have encountered one of the big problems with this `setwd(file_path)` approach: as it only takes absolute paths like this one: "/Users/felixlennert/Library/Mobile Documents/com~apple~CloudDocs/phd/teaching/hhs-stockholm/fall2021/scripts/", no other person will be able to run this script without making any changes^[This becomes especially painful if you teach R to your students and have to grade 20 submissions and, hence, have to paste your personal directory's file path into each of these submissions.]. Just to be clear: there are no two machines which have the exact same file structure.  

This is where RStudio Projects come into play: they make every file path relative. The Project file (ends with .Rproj) basically sets the working directory to the folder it is in. Hence, if you want to send your work to a peer or a teacher, just send a folder which also contains the .Rproj file and they will be able to work on your project without the hassle of pasting file paths into `setwd()` commands.

### How to create an RStudio Project?

I strongly suggest that you set up a project which is dedicated to this workshop

1. In RStudio, click File >> New Project… 
2. A windows pops up which lets you select between "New Directory", "Existing Directory", and "Version Control." The first option creates a new folder which is named after your project, the second one "associates a project with an existing working directory," and the third one only applies to version control (like, for instance, GitHub) users. I suggest that you click "New Directory".
3. Now you need to specify the type of the project (Empty project, R package, or Shiny Web Application). In our case, you will need a "new project." Hit it!  
4. The final step is to choose the folder the project will live in. If you have already created a folder which is dedicated to this course, choose this one, and let the project live in there as a sub-directory.
5. When you write code for our course in the future, you *first* open the R project -- by double-clicking the .Rproj file -- and then create either a new script or open a former one (e.g., by going through the "Files" tab in the respective pane which will show the right directory already.)

## The working directory in R

As mentioned when introducing RStudio Projects, there are two kinds of file paths you can provide R with: absolute and relative paths.

The absolute path for this script on my machine looks like this: "/Users/felixlennert/Documents/phd/teaching/data-prep_2days/data-cleaning-book/tidy-data.qmd".   
If you are on a Windows machine and copy file paths: R uses the file path separator `\` as a so-called escape character -- hence, it does not recognize it as a file path separator. You can address this problem by either using double back-slashes `\\` or using a normal slash, `/`, instead.

There is always a working directory you are in. You can obtain your working directory using `getwd()`. Relative paths then just build upon it. If you want to change your working directory, use `setwd()`. 

*Please note that I included the former two paragraphs just for the record. You should never use absolute paths, except for if you are planning to keep the same machine for the rest of your life and never change any of your file structure. You are not. Hence, please use RStudio Projects.*^[you can find the thoughts of one of the main author of the `knitr` package on working directories [here](https://groups.google.com/forum/#!topic/knitr/knM0VWoexT0)]

If you are using RStudio Projects, your working directory defaults to the folder your `.Rproj` file is stored in. So, I guess you could immediately see the merit of using RStudio projects: by using them, you can do away with all the faff of setting working directories, copying crazy long absolute paths, and, relatedly, searching for typos in them.

If you are working in RMarkdown, or quarto, its successor, the working directory is where your RMarkdown document is stored in.

### Further links

* Hadley Wickham and Garrett Grolemund wrote an [entire chapter](https://r4ds.had.co.nz/workflow-projects.html#rstudio-projects) in R4DS on Projects.  
* Need more motivation? Jennifer Bryan tells you under which circumstances she would set your machine on fire: [Project-oriented workflow](https://www.tidyverse.org/blog/2017/12/workflow-vs-script/). 
* If you have created your project folder and are now unsure how to structure it, read Chris von Csefalvay's [blog post](https://chrisvoncsefalvay.com/2018/08/09/structuring-r-projects/) on how to do it.

## `readr`'s general functions…

In general, importing data with `readr` is pretty hassle-free: the hardest thing about it is calling the right function. It usually takes care of the rest itself, parsing columns properly, etc. However, sometimes you need to specify additional arguments.

The following unordered list shows the most common `read_*()` functions. Usually, you can simply provide them a file path and they load in the data and return a Tibble. If your data is in a compressed file with the extension `.gz`, `.bz2`, `.xz`, or `.zip`, `readr` will automatically uncompress it. If the file is stored online, you can provide a URL starting with `http://`, `https://`, `ftp://`, or `ftps://`. `readr` will automatically take care of the download process.

* `read_csv("file.csv")` reads comma delimited files      
* `read_csv2("file.csv")` reads semi-colon delimited files and treats commas as decimal separator          
* `read_delim("file.txt", delim = "|")` reads files which are delimited by whatever delimiter you specify (`|` in this case)        
* `read_fwf("file.fwf", col_positions = c(1, 3, 5))` reads fixed width files. Here, some sort of data on the columns must be provided, e.g., their positions in the file       
* If the values are separated by whitespace, you can also use `read_tsv("file.tsv")` or `read_table("file.tsv")`

## …and their additional arguments

Also, all these functions share certain arguments which just need to be included in the call. In the following, I will enumerate the most useful ones.

* If your file does not have a header (most of the time, column names), provide `col_names = FALSE`. The resulting Tibble will have `X1 … Xn` as column names      
* If your file does not have column names, but you want the resulting Tibble to have some, you can specify them with `col_names = c("a", "b", "c")`. It takes a character vector.     
* If there are rows you do not want to be considered, you can use `skip =`. For instance, `read_csv("file.csv", skip = 6)` reads everything but the first six data rows (the very first row is not taken into consideration as well)       
* Sometimes the original creator of your data set might go across missing values differently than you would want it to. `na =` can be used to specify which values shall be considered missing. If your missings are coded as 99 and 999, for instance, you can address that in the read-in process already by using `read_csv("file.csv", na = c("99", "999"))`. Please note that it takes a character vector as argument     
* In some data sets, the first rows consists of comments that start with particular signs or special characters. Using `comment = ` allows you to skip these lines. For instance, `read_csv("file.csv", comment = "#")` drops all the rows that beginn with a hash. 

### Column types

As you have already learned in the script before, a Tibble consists of multiple vectors of the same length. The vectors can be of different types. When you read in data using `readr`, it will print out the column types it has guessed. When you read in data, you must ascribe it to an object in your environment. The following code reads in a `.csv` file with data on the 100 most-played songs on Spotify in 2018 and stores it in the object `spotify_top100_2018`.

```{r}
library(tidyverse)
# library(readr) --> no need to load readr, it's part of the core tidyverse
spotify_top100_2018 <- read_csv("https://www.dropbox.com/s/z8d6irpjdohdktf/spotify2018.csv?dl=1")
```

If your data is well-behaved, R will guess the vector types correctly and everything will run smoothly. However, sooner or later you will stumble across a data set which is not well-behaved. This is where knowing how to fine-tune your parsing process up-front will eventually save you a lot of head scratching.    

But how does parsing actually look like. Well, `readr`'s parsing functions take a character vector and return a more specialized vector.

```{r}
parse_double(c("1", "2", "3"))
```

So far so good. What `readr`does when it reads in your data sets is that it takes the first 1,000 values of every column and tries to guess the correct data type. This can be emulated using `guess_parser()` and `parse_guess()`. Both functions take a character vector as input. The former one returns the guessed type, the latter returns a vector which is parsed to the type it has guessed. 

```{r}
guess_parser("2009-04-23")
str(parse_guess("2009-04-23"))
```

The heuristic it uses is fairly simple yet robust. However, there are common cases when you might run into problems with different data types. In the following, I will show you the two most common ones. The first one regards numeric data, the second one data on date and time.

#### Numbers

Parsing numbers should be straight-forward, right, so what could possibly go wrong?    

Well…    

* Decimal points       
* Special characters ($, %, §, €)   
* So-called grouping characters such as 1,000,000 (USA) or 1.000.000 (Germany) or 1'000'000 (Switzerland)    

The problem with decimale points (-- and commas) can be addresses by specifying a `locale`. Compare:

```{r}
parse_double("1,3")
parse_double("1,3", locale = locale(decimal_mark = ","))
```

The special character problem can be addressed using `parse_number` instead of `parse_double`: it will ignore the special characters.

```{r}
parse_number("1.5€")
```

The final problem, grouping characters, can be addressed using another `locale`.

```{r}
parse_number("1.300.000", locale = locale(grouping_mark = "."))
```

#### Date and time

Date vectors in R are numeric vectors indicating how many days have passed since 1970. Date-Time vectors indicate the seconds that have passed since 1970-01-01 00:00:00. Time vectors indicate the number of seconds that have passed since midnight.

The `parse_*()` functions expect the vectors to be in a certain format:

* `parse_datetime()` expects the input to follow the ISO8601 standard. The times components must be ordered from biggest to smallest: year, month, day, hour, minute, second.

```{r}
parse_datetime("2000-02-29T2000")
```

* `parse_date()` wants a four digit year, two digit month, and two digit day. They can be separated by either "-" or "/". 

```{r}
parse_date("2000-02-29")
parse_date("2000/02/29")
```

Do you wonder why I chose 2000-02-29? It's R's birthday…

* `parse_time()` needs at least hours and minutes, seconds are optional. They need to be separated by colons. There is no proper built-in class for time data in Base R. Hence, I will use the `hms` package here.

```{r}
library(hms)
parse_time("20:15:00")
parse_time("20:15") # both works
```

When it comes to dates, you can also build your own format. Just mash together the following pieces:

* Year: `%Y` -- year in 4 digits; `%y` -- year in two digits following this rule: 00--69 = 2000--2069, 70--99 = 1970--1999      
* Month: `%m` -- two digits; `%b` -- abbreviated name (e.g., "Nov"); `%B` -- full name (e.g., "November")         
* Day: `%d` -- two digits           
* Time: `%H` -- hour, 0--23; `%h` -- hour, 1--12, must come together with `%p` -- a.m./p.m. indicator; `%M` -- minutes; `%S` -- integer seconds; `%Z` time zone -- `America/Chicago` for instance    
* Non-digits: `%.` skips one non-digit character; `%*` skips any number of non-digits

You might see that there can emerge problems with this. You might, for example, have something like this:

```{r}
example_date <- "29. Februar 2000"
```

So how can you parse this date with a German month name? Again, you can use `locale =`.

```{r}
date_names_langs() # what could be the proper abbreviation?
parse_date(example_date, format = "%d%. %B %Y", locale = locale(date_names = "de"))
```

Now you know how to parse number and date vectors yourself. This is nice, but normally you do not want to read in data, put it into character vectors and then parse it to the right data format. You want to read in a data set and get a Tibble whose columns consist of data which have been parsed to the right type already.

#### Parsing entire files

As mentioned earlier, the `read_*` functions take the first 1000 rows and then guess the columns format. I emulated this using the `guess_parser()` function.

If `readr` finds values in a column that do not match the type of the column which it has guessed in first place, or entirely fails to parse a column (e.g., because it only consists of `NAs`), it returns parsing failures. They can be obtained using `problems()`. 

```{r}
challenge <- read_csv(readr_example("challenge.csv"))
head(challenge)
problems(challenge)
```

When looking at the parsing failures here, what catches the eye is that the first 1000 values of `challenge$y` seem to be NA. Because `readr` only takes the first 1000 rows into account, it parses `challenge$y` as `logical`. However, it should be considered a `date` column. You can specify this using `col_types =`:

```{r}
challenge_w_date <- read_csv(readr_example("challenge.csv"),
                             col_types = cols(
                               x = col_number(),
                               y = col_date()
                             ))
```

In general, every `parse_*` function has its `col_*` counterpart.

If you want to read in data and change the column specifications, there is a little shortcut:

First, read in your data set:

```{r}
challenge <- read_csv(readr_example("challenge.csv"))
```

Second, you can copy the column specification from the output to your clipboard:

```{r}
#This part: 
#cols(
#  x = col_double(),
#  y = col_logical()
#)
```

Third, provide it your `read_csv()` call as a `col_types =` argument (by simply pasting it):

```{r}
#challenge <- read_csv(readr_example("challenge.csv"),
#                     col_types = cols(
#                       x = col_double(),
#  needs to be modified --> y = col_logical()
#                            ))
```

Fourth, modify the argument:

```{r}
#challenge_w_date <- read_csv(readr_example("challenge.csv"),
#                             col_types = cols(
#                               x = col_number(),
#  modified -->                 y = col_date()
#                            ))
```

Fifth, read it in:

```{r}
challenge_w_date <- read_csv(readr_example("challenge.csv"),
                      col_types = cols(
                        x = col_number(),
                        y = col_date()
                      ))
```

## `.rds` and `.RData`files

`.rds` files can be used to store singular R-specific objects (such as lists), `.RData` files can be used to store multiple R-specific objects. The former can be read in using `read_rds("file.rds")`, the latter with `load("file.RData")`. More on `read_rds()` [here](https://readr.tidyverse.org/reference/read_rds.html) and `.RData` [here](http://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata)

# Write data 

## `write_csv()`

Writing data is fairly straight-forward. Most of the times, you will work with plain Tibbles which consist of different kinds of vectors except for lists. If you want to store them, I recommend you to simply use `write_csv(tibble, path = "file.csv")`. If you plan on working on the `.csv` file in Excel, use `write_excel_csv(tibble, path = "file.csv")`

## `write_rds()`

Sometimes, however, it might be impossible to create a `.csv` file of your data -- e.g., if you want to store a list. This is what you can use `write_rds(r_specific_object, path = "file.rds")` for. 

## `save()`

Akin to `.rds` files are `.RData` files. They can contain multiple objects and be written using `save(r_specific_object_1, r_specific_object_2, r_specific_object_n, file = "file.RData")`. You can save your entire workspace as well by calling `save.image(file = "file.RData")`.

## Alternative ways to read in and write data

There do also other packages exist for different data types. I will explain the ones which might be of particular use for you and their main-functions only briefly.

### `haven`

You can use `haven` [@wickham2020c] for reading and writing SAS (suffixes `.sas7bdat`, `.sas7bcat`, and `.xpt`),  SPSS (suffixes `.sav` and `.por`), and STATA (suffix `.dta`) files.

The functions then are:   

* `read_sas("file.sas7bdate"` and `write_sas(tibble, "file.sas7bdat")` for both `.sas7bdat` and `.sas7bcat` files. `read_xpt("file.xpt")` reads `.xpt` files    
* `read_sav("file.sav")` and `read_por("file.por")` for `.sav` and `.por` files. `write_sav(tibble, "file.sav"` writes a the Tibble `tibble` to the file `file.sav`   
* `read_dta("file.dta")` and `write_dta(tibble, "file.dta")` read and write `.dta` files

The additional arguments can be found in the [vignette](https://cran.r-project.org/web/packages/haven/vignettes/semantics.html).

### `readxl`

`readxl` [@wickham2019e] can be used to read Excel files. `read_excel("file.xls")` works for both `.xls` and `.xlsx` files alike. It guesses the data type from the suffix. Excel files often consist of multiple sheets. `excel_sheets("file.xlsx")` returns the name of the singular sheets. When dealing with an Excel file that contains multiple sheets, you need to specify the sheet you are after in the `read_excel()` function: `read_excel("file.xlsx", sheet = "sheet_1")`. Please note that it only takes one sheet at a time. 

More on the `readxl` package can be found [here](https://readxl.tidyverse.org).

### `vroom`

`vroom` has been introduced recently. It claims to be able to read in delimited files with up to 1.4 GB/s. Regarding its arguments, `vroom` works in the same way as the `read_*()` functions from the `readr` package. I would recommend you to use `vroom` as soon as your dataset's size exceeds ~100 MB.

More on `vroom` [here](https://vroom.r-lib.org/reference/vroom.html) and [here](https://dcl-wrangle.stanford.edu/read-write.html).

### Further readings

* [Information on working directories](https://support.rstudio.com/hc/en-us/articles/200711843-Working-Directories-and-Workspaces)    
* Websites of the singular packages: [readr](https://readr.tidyverse.org), [haven](https://haven.tidyverse.org), [readxl](https://readxl.tidyverse.org), [vroom](https://vroom.r-lib.org)  
* `readr` [Cheatsheet](https://rawgit.com/rstudio/cheatsheets/master/data-import.pdf)   
* Chapter in R for Data Science [@wickham2016a] regarding [data import](https://r4ds.had.co.nz/data-import.html)

